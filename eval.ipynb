{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk\n",
      "  Downloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.5 MB 29.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pandas in /home/mxtan/.local/lib/python3.8/site-packages (2.0.3)\n",
      "Requirement already satisfied: click in /home/mxtan/.local/lib/python3.8/site-packages (from nltk) (8.1.7)\n",
      "Collecting joblib\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "\u001b[K     |████████████████████████████████| 301 kB 86.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: tqdm in /home/mxtan/.local/lib/python3.8/site-packages (from nltk) (4.66.4)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/mxtan/.local/lib/python3.8/site-packages (from nltk) (2024.5.15)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/mxtan/.local/lib/python3.8/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/mxtan/.local/lib/python3.8/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/mxtan/.local/lib/python3.8/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: numpy>=1.20.3; python_version < \"3.10\" in /home/mxtan/.local/lib/python3.8/site-packages (from pandas) (1.24.4)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas) (1.14.0)\n",
      "Installing collected packages: joblib, nltk\n",
      "Successfully installed joblib-1.4.2 nltk-3.8.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting textstat\n",
      "  Downloading textstat-0.7.3-py3-none-any.whl (105 kB)\n",
      "\u001b[K     |████████████████████████████████| 105 kB 35.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pyphen\n",
      "  Downloading pyphen-0.15.0-py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 90.3 MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: pyphen, textstat\n",
      "Successfully installed pyphen-0.15.0 textstat-0.7.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: transformers in /home/mxtan/.local/lib/python3.8/site-packages (4.38.2)\n",
      "Requirement already satisfied: torch in /home/mxtan/.local/lib/python3.8/site-packages (2.3.0)\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.3.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 11.1 MB 35.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/lib/python3/dist-packages (from transformers) (5.3.1)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /home/mxtan/.local/lib/python3.8/site-packages (from transformers) (0.15.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/mxtan/.local/lib/python3.8/site-packages (from transformers) (2024.5.15)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/mxtan/.local/lib/python3.8/site-packages (from transformers) (24.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /home/mxtan/.local/lib/python3.8/site-packages (from transformers) (0.23.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/mxtan/.local/lib/python3.8/site-packages (from transformers) (1.24.4)\n",
      "Requirement already satisfied: requests in /usr/lib/python3/dist-packages (from transformers) (2.22.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/mxtan/.local/lib/python3.8/site-packages (from transformers) (4.66.4)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/mxtan/.local/lib/python3.8/site-packages (from transformers) (0.4.3)\n",
      "Requirement already satisfied: filelock in /home/mxtan/.local/lib/python3.8/site-packages (from transformers) (3.14.0)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /home/mxtan/.local/lib/python3.8/site-packages (from torch) (2.20.5)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /home/mxtan/.local/lib/python3.8/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: sympy in /home/mxtan/.local/lib/python3.8/site-packages (from torch) (1.12.1)\n",
      "Requirement already satisfied: networkx in /home/mxtan/.local/lib/python3.8/site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /home/mxtan/.local/lib/python3.8/site-packages (from torch) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /home/mxtan/.local/lib/python3.8/site-packages (from torch) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /home/mxtan/.local/lib/python3.8/site-packages (from torch) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /home/mxtan/.local/lib/python3.8/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /home/mxtan/.local/lib/python3.8/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: jinja2 in /usr/lib/python3/dist-packages (from torch) (2.10.1)\n",
      "Requirement already satisfied: fsspec in /home/mxtan/.local/lib/python3.8/site-packages (from torch) (2023.10.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/mxtan/.local/lib/python3.8/site-packages (from torch) (4.12.1)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /home/mxtan/.local/lib/python3.8/site-packages (from torch) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /home/mxtan/.local/lib/python3.8/site-packages (from torch) (11.4.5.107)\n",
      "Requirement already satisfied: triton==2.3.0; platform_system == \"Linux\" and platform_machine == \"x86_64\" and python_version < \"3.12\" in /home/mxtan/.local/lib/python3.8/site-packages (from torch) (2.3.0)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /home/mxtan/.local/lib/python3.8/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /home/mxtan/.local/lib/python3.8/site-packages (from torch) (8.9.2.26)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /home/mxtan/.local/lib/python3.8/site-packages (from scikit-learn) (1.4.2)\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Downloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /home/mxtan/.local/lib/python3.8/site-packages (from scikit-learn) (1.10.1)\n",
      "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /home/mxtan/.local/lib/python3.8/site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/mxtan/.local/lib/python3.8/site-packages (from nvidia-cusparse-cu12==12.1.0.106; platform_system == \"Linux\" and platform_machine == \"x86_64\"->torch) (12.5.40)\n",
      "Installing collected packages: threadpoolctl, scikit-learn\n",
      "Successfully installed scikit-learn-1.3.2 threadpoolctl-3.5.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/mxtan/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
      "[nltk_data] Downloading package punkt to /home/mxtan/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pip install nltk pandas\n",
    "%pip install textstat\n",
    "%pip install transformers torch scikit-learn\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('human_res.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feedback word count\n",
    "df['feedback'] = df['feedback'].astype(str)\n",
    "df['wc'] = df['feedback'].apply(lambda x: len(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feedback sentence count\n",
    "def count_sentences(feedback):\n",
    "    sentences = sent_tokenize(feedback)\n",
    "    return len(sentences)\n",
    "\n",
    "df['sc'] = df['feedback'].apply(count_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fleisch kincaid\n",
    "import pandas as pd\n",
    "import textstat\n",
    "df['fk'] = df['feedback'].apply(textstat.flesch_reading_ease)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TTR\n",
    "import nltk\n",
    "def calculate_ttr(feedback):\n",
    "    tokens = word_tokenize(feedback)\n",
    "    unique_tokens = set(tokens)\n",
    "    ttr = len(unique_tokens) / len(tokens) if tokens else 0\n",
    "    return ttr\n",
    "\n",
    "df['ttr'] = df['feedback'].apply(calculate_ttr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fluency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inverse perplexity\n",
    "import torch\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "\n",
    "# Load pre-trained GPT-2 model and tokenizer\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "\n",
    "# Function to calculate inverse perplexity\n",
    "def calculate_inverse_perplexity(feedback):\n",
    "    inputs = tokenizer(feedback, return_tensors='pt')\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs, labels=inputs['input_ids'])\n",
    "    loss = outputs.loss.item()\n",
    "    perplexity = torch.exp(torch.tensor(loss)).item()\n",
    "    inverse_perplexity = 1 / perplexity if perplexity != 0 else 0\n",
    "    return inverse_perplexity\n",
    "\n",
    "df['inverse_perplexity'] = df['feedback'].apply(calculate_inverse_perplexity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Specificity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Content Word Density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "def calculate_content_word_density(feedback):\n",
    "    tokens = word_tokenize(feedback)\n",
    "    pos_tags = pos_tag(tokens)\n",
    "    # Content words are nouns, verbs, adjectives, and adverbs\n",
    "    content_words = [word for word, pos in pos_tags if pos.startswith('NN') or pos.startswith('VB') or pos.startswith('JJ') or pos.startswith('RB')]\n",
    "    content_word_density = len(content_words) / len(tokens) if tokens else 0\n",
    "    \n",
    "    return content_word_density\n",
    "\n",
    "df['content_word_density'] = df['feedback'].apply(calculate_content_word_density)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uptake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def. uptake as overlap\n",
    "def calculate_uptake(excerpt, feedback):\n",
    "    # Tokenize both excerpt and feedback comment\n",
    "    excerpt_tokens = set(word_tokenize(excerpt.lower()))\n",
    "    feedback_tokens = set(word_tokenize(feedback.lower()))\n",
    "    \n",
    "    # Find common words\n",
    "    common_words = excerpt_tokens.intersection(feedback_tokens)\n",
    "    \n",
    "    # Calculate uptake as the ratio of common words to total words in the excerpt\n",
    "    uptake = len(common_words) / len(excerpt_tokens) if excerpt_tokens else 0\n",
    "    \n",
    "    return uptake\n",
    "\n",
    "# Apply the function to calculate uptake for each row\n",
    "df['uptake'] = df.apply(lambda row: calculate_uptake(row['excerpt'], row['feedback']), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Context Relevance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# cosine similarity of embeddings\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "def get_embeddings(text):\n",
    "    inputs = tokenizer(text, return_tensors='pt', truncation=True, padding=True, max_length=512)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    embeddings = outputs.last_hidden_state.mean(dim=1).squeeze().numpy()\n",
    "    return embeddings\n",
    "\n",
    "# Function to calculate cosine similarity between embeddings\n",
    "def calculate_cosine_similarity(excerpt, feedback):\n",
    "    excerpt_embedding = get_embeddings(excerpt)\n",
    "    feedback_embedding = get_embeddings(feedback)\n",
    "    similarity = cosine_similarity([excerpt_embedding], [feedback_embedding])[0][0]\n",
    "    return similarity\n",
    "\n",
    "# Apply the function to calculate cosine similarity for each row\n",
    "df['cosine_similarity'] = df.apply(lambda row: calculate_cosine_similarity(row['excerpt'], row['feedback']), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantic Focus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pronouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_person_singular = {'i', 'me', 'my', 'mine'}\n",
    "second_person = {'you', 'your', 'yours'}\n",
    "first_person_plural = {'we', 'us', 'our', 'ours'}\n",
    "\n",
    "def count_pronouns(feedback, pronoun_set):\n",
    "    tokens = word_tokenize(feedback.lower())\n",
    "    pronoun_count = sum(1 for token in tokens if token in pronoun_set)\n",
    "    return pronoun_count\n",
    "\n",
    "df['pronoun_fps'] = df['feedback'].apply(lambda x: count_pronouns(x, first_person_singular))\n",
    "df['pronoun_sp'] = df['feedback'].apply(lambda x: count_pronouns(x, second_person))\n",
    "df['pronoun_fpp'] = df['feedback'].apply(lambda x: count_pronouns(x, first_person_plural))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "wh_words = {'what', 'where', 'when', 'which', 'who', 'whom', 'whose', 'why', 'how'}\n",
    "auxiliary_verbs = {'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'do', 'does', 'did', 'will', 'would', 'shall', 'should', 'can', 'could', 'may', 'might', 'must'}\n",
    "helping_verbs = {\"is\", \"am\", \"can\", \"are\", \"do\", \"does\"}\n",
    "\n",
    "def is_question(sentence):\n",
    "    tokens = word_tokenize(sentence)\n",
    "    return sentence.strip().endswith('?') or (tokens and (tokens[0] in wh_words or tokens[0] in helping_verbs))\n",
    "\n",
    "def count_wh_questions(feedback):\n",
    "    sentences = sent_tokenize(feedback.lower())\n",
    "    wh_question_count = sum(1 for sentence in sentences if is_question(sentence) and word_tokenize(sentence)[0] in wh_words)\n",
    "    return wh_question_count\n",
    "\n",
    "def count_yes_no_questions(feedback):\n",
    "    sentences = sent_tokenize(feedback.lower())\n",
    "    yes_no_question_count = sum(1 for sentence in sentences if is_question(sentence) and word_tokenize(sentence)[0] in auxiliary_verbs)\n",
    "    return yes_no_question_count\n",
    "\n",
    "df['wh_question_count'] = df['feedback'].apply(count_wh_questions)\n",
    "df['yes_no_question_count'] = df['feedback'].apply(count_yes_no_questions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()\n",
    "df.to_csv('human_meta_pt1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tid</th>\n",
       "      <th>grade</th>\n",
       "      <th>prompt</th>\n",
       "      <th>essay</th>\n",
       "      <th>essayid</th>\n",
       "      <th>excerpt</th>\n",
       "      <th>feedback</th>\n",
       "      <th>startidx</th>\n",
       "      <th>endidx</th>\n",
       "      <th>commentid</th>\n",
       "      <th>...</th>\n",
       "      <th>ttr</th>\n",
       "      <th>inverse_perplexity</th>\n",
       "      <th>content_word_density</th>\n",
       "      <th>uptake</th>\n",
       "      <th>cosine_similarity</th>\n",
       "      <th>pronoun_fps</th>\n",
       "      <th>pronoun_sp</th>\n",
       "      <th>pronoun_fpp</th>\n",
       "      <th>wh_question_count</th>\n",
       "      <th>yes_no_question_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rfQv3LPBikeoFIE1NyA3</td>\n",
       "      <td>ms</td>\n",
       "      <td>Some of your friends perform community service...</td>\n",
       "      <td>Dear Principal,\\n\\nI have heard you are having...</td>\n",
       "      <td>1CE6C10B9683</td>\n",
       "      <td>i</td>\n",
       "      <td>Capital and introductory phrase</td>\n",
       "      <td>255</td>\n",
       "      <td>258</td>\n",
       "      <td>1718398386391</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.507323</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rfQv3LPBikeoFIE1NyA3</td>\n",
       "      <td>ms</td>\n",
       "      <td>Some of your friends perform community service...</td>\n",
       "      <td>Dear Principal,\\n\\nI have heard you are having...</td>\n",
       "      <td>1CE6C10B9683</td>\n",
       "      <td>e a</td>\n",
       "      <td>Introductory phrase</td>\n",
       "      <td>548</td>\n",
       "      <td>551</td>\n",
       "      <td>1718398439880</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.654442</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rfQv3LPBikeoFIE1NyA3</td>\n",
       "      <td>ms</td>\n",
       "      <td>Some of your friends perform community service...</td>\n",
       "      <td>Dear Principal,\\n\\nI have heard you are having...</td>\n",
       "      <td>1CE6C10B9683</td>\n",
       "      <td>dyer</td>\n",
       "      <td>wrong word</td>\n",
       "      <td>1137</td>\n",
       "      <td>1141</td>\n",
       "      <td>1718398530582</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000170</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.683321</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rfQv3LPBikeoFIE1NyA3</td>\n",
       "      <td>ms</td>\n",
       "      <td>Some of your friends perform community service...</td>\n",
       "      <td>Dear Principal,\\n\\nI have heard you are having...</td>\n",
       "      <td>1CE6C10B9683</td>\n",
       "      <td>know it may sound funny but picking up trash ...</td>\n",
       "      <td>run-on sentence</td>\n",
       "      <td>1267</td>\n",
       "      <td>1487</td>\n",
       "      <td>1718398574934</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000780</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.426005</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rfQv3LPBikeoFIE1NyA3</td>\n",
       "      <td>ms</td>\n",
       "      <td>Some of your friends perform community service...</td>\n",
       "      <td>Dear Principal,\\n\\nI have heard you are having...</td>\n",
       "      <td>1CE6C10B9683</td>\n",
       "      <td>or example if one student did community servic...</td>\n",
       "      <td>Good example</td>\n",
       "      <td>791</td>\n",
       "      <td>875</td>\n",
       "      <td>1718398626223</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000219</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.460753</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    tid grade  \\\n",
       "0  rfQv3LPBikeoFIE1NyA3    ms   \n",
       "1  rfQv3LPBikeoFIE1NyA3    ms   \n",
       "2  rfQv3LPBikeoFIE1NyA3    ms   \n",
       "3  rfQv3LPBikeoFIE1NyA3    ms   \n",
       "4  rfQv3LPBikeoFIE1NyA3    ms   \n",
       "\n",
       "                                              prompt  \\\n",
       "0  Some of your friends perform community service...   \n",
       "1  Some of your friends perform community service...   \n",
       "2  Some of your friends perform community service...   \n",
       "3  Some of your friends perform community service...   \n",
       "4  Some of your friends perform community service...   \n",
       "\n",
       "                                               essay       essayid  \\\n",
       "0  Dear Principal,\\n\\nI have heard you are having...  1CE6C10B9683   \n",
       "1  Dear Principal,\\n\\nI have heard you are having...  1CE6C10B9683   \n",
       "2  Dear Principal,\\n\\nI have heard you are having...  1CE6C10B9683   \n",
       "3  Dear Principal,\\n\\nI have heard you are having...  1CE6C10B9683   \n",
       "4  Dear Principal,\\n\\nI have heard you are having...  1CE6C10B9683   \n",
       "\n",
       "                                             excerpt  \\\n",
       "0                                                 i    \n",
       "1                                                e a   \n",
       "2                                               dyer   \n",
       "3   know it may sound funny but picking up trash ...   \n",
       "4  or example if one student did community servic...   \n",
       "\n",
       "                          feedback  startidx  endidx      commentid  ...  ttr  \\\n",
       "0  Capital and introductory phrase       255     258  1718398386391  ...  1.0   \n",
       "1              Introductory phrase       548     551  1718398439880  ...  1.0   \n",
       "2                       wrong word      1137    1141  1718398530582  ...  1.0   \n",
       "3                  run-on sentence      1267    1487  1718398574934  ...  1.0   \n",
       "4                     Good example       791     875  1718398626223  ...  1.0   \n",
       "\n",
       "   inverse_perplexity  content_word_density  uptake cosine_similarity  \\\n",
       "0            0.000089                  0.75  0.0000          0.507323   \n",
       "1            0.000053                  1.00  0.0000          0.654442   \n",
       "2            0.000170                  1.00  0.0000          0.683321   \n",
       "3            0.000780                  1.00  0.0000          0.426005   \n",
       "4            0.000219                  1.00  0.0625          0.460753   \n",
       "\n",
       "   pronoun_fps  pronoun_sp  pronoun_fpp  wh_question_count  \\\n",
       "0            0           0            0                  0   \n",
       "1            0           0            0                  0   \n",
       "2            0           0            0                  0   \n",
       "3            0           0            0                  0   \n",
       "4            0           0            0                  0   \n",
       "\n",
       "   yes_no_question_count  \n",
       "0                      0  \n",
       "1                      0  \n",
       "2                      0  \n",
       "3                      0  \n",
       "4                      0  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "df = pd.read_csv('human_meta_pt1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['feedback'] = df['feedback'].astype(str)\n",
    "df['excerpt'] = df['excerpt'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non-Dialogic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mxtan/.local/lib/python3.8/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "  0%|          | 0/1163 [00:00<?, ?it/s]/home/mxtan/.local/lib/python3.8/site-packages/transformers/pipelines/base.py:1157: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "100%|██████████| 1163/1163 [00:09<00:00, 129.08it/s]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "pipe = pipeline(\"text-classification\", model=\"meiflwr/nondialogic_feedback\", device = 0)\n",
    "def get_dro(excerpt, feedback):\n",
    "    out = []\n",
    "    dro_out = pipe([{'text': feedback, 'text_pair': excerpt}])\n",
    "    if dro_out[0]['label'] == 'LABEL_1':\n",
    "        out.append(1)\n",
    "    else:\n",
    "        out.append(0)\n",
    "    return out\n",
    "\n",
    "tqdm.pandas()\n",
    "df['ND'] = df.progress_apply(lambda row: get_dro(row['excerpt'], row['feedback']), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non-Revision-Oriented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mxtan/.local/lib/python3.8/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "100%|██████████| 1163/1163 [00:36<00:00, 31.61it/s]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "pipe = pipeline(\"text-classification\", model=\"meiflwr/nonrevisionoriented_feedback\")\n",
    "def get_dro(excerpt, feedback):\n",
    "    out = []\n",
    "    dro_out = pipe([{'text': feedback, 'text_pair': excerpt}])\n",
    "    if dro_out[0]['label'] == 'LABEL_1':\n",
    "        out.append(1)\n",
    "    else:\n",
    "        out.append(0)\n",
    "    return out\n",
    "\n",
    "tqdm.pandas()\n",
    "df['NRO'] = df.progress_apply(lambda row: get_dro(row['excerpt'], row['feedback']), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pure Praise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mxtan/.local/lib/python3.8/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "100%|██████████| 1163/1163 [00:38<00:00, 30.58it/s]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "pipe = pipeline(\"text-classification\", model=\"meiflwr/praise_feedback\")\n",
    "def get_dro(excerpt, feedback):\n",
    "    out = []\n",
    "    dro_out = pipe([{'text': feedback, 'text_pair': excerpt}])\n",
    "    if dro_out[0]['label'] == 'LABEL_1':\n",
    "        out.append(1)\n",
    "    else:\n",
    "        out.append(0)\n",
    "    return out\n",
    "\n",
    "tqdm.pandas()\n",
    "df['PP'] = df.progress_apply(lambda row: get_dro(row['excerpt'], row['feedback']), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Power-Affirming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mxtan/.local/lib/python3.8/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "100%|██████████| 1163/1163 [00:35<00:00, 32.97it/s]\n",
      "100%|██████████| 1163/1163 [00:37<00:00, 30.66it/s]\n",
      "100%|██████████| 1163/1163 [00:36<00:00, 31.86it/s]\n"
     ]
    }
   ],
   "source": [
    "# Use a pipeline as a high-level helper\n",
    "from transformers import pipeline\n",
    "pipe1 = pipeline(\"text-classification\", model=\"meiflwr/poweraffirming_feedback_skew1\")\n",
    "pipe2 = pipeline(\"text-classification\", model=\"meiflwr/poweraffirming_feedbak_skew2\")\n",
    "pipe3 = pipeline(\"text-classification\", model=\"meiflwr/poweraffirming_feedback_skew3\")\n",
    "\n",
    "def get_pa(excerpt, feedback, pipeline):\n",
    "  reward = pipeline([{'text': feedback, 'text_pair': excerpt}])\n",
    "  return reward[0]['score']\n",
    "\n",
    "tqdm.pandas()\n",
    "df['pa1'] = df.progress_apply(lambda row: get_pa(row['excerpt'], row['feedback'], pipe1), axis=1)\n",
    "df['pa2'] = df.progress_apply(lambda row: get_pa(row['excerpt'], row['feedback'], pipe2), axis=1)\n",
    "df['pa3'] = df.progress_apply(lambda row: get_pa(row['excerpt'], row['feedback'], pipe3), axis=1)\n",
    "\n",
    "# Calculate the variance of the pa-scores\n",
    "df['pa_var'] = df[['pa1', 'pa2', 'pa3']].var(axis=1)\n",
    "df['pa_mean'] = df[['pa1', 'pa2', 'pa3']].mean(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('human_res_meta.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
