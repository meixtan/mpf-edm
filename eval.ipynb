{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install nltk pandas\n",
    "%pip install textstat\n",
    "%pip install transformers torch scikit-learn\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: language-tool-python in /home/mxtan/.local/lib/python3.8/site-packages (2.8)\n",
      "Requirement already satisfied: wheel in /usr/lib/python3/dist-packages (from language-tool-python) (0.34.2)\n",
      "Requirement already satisfied: pip in /usr/lib/python3/dist-packages (from language-tool-python) (20.0.2)\n",
      "Requirement already satisfied: requests in /usr/lib/python3/dist-packages (from language-tool-python) (2.22.0)\n",
      "Requirement already satisfied: tqdm in /home/mxtan/.local/lib/python3.8/site-packages (from language-tool-python) (4.66.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install language-tool-python\n",
    "import language_tool_python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('human_res_asap.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feedback word count\n",
    "df['feedback'] = df['feedback'].astype(str)\n",
    "df['wc'] = df['feedback'].apply(lambda x: len(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feedback sentence count\n",
    "def count_sentences(feedback):\n",
    "    sentences = sent_tokenize(feedback)\n",
    "    return len(sentences)\n",
    "\n",
    "df['sc'] = df['feedback'].apply(count_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fleisch kincaid\n",
    "import pandas as pd\n",
    "import textstat\n",
    "df['fk'] = df['feedback'].apply(textstat.flesch_reading_ease)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TTR\n",
    "import nltk\n",
    "def calculate_ttr(feedback):\n",
    "    tokens = word_tokenize(feedback)\n",
    "    unique_tokens = set(tokens)\n",
    "    ttr = len(unique_tokens) / len(tokens) if tokens else 0\n",
    "    return ttr\n",
    "\n",
    "df['ttr'] = df['feedback'].apply(calculate_ttr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fluency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mxtan/.local/lib/python3.8/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# inverse perplexity\n",
    "import torch\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "\n",
    "# Load pre-trained GPT-2 model and tokenizer\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "\n",
    "# Function to calculate inverse perplexity\n",
    "def calculate_inverse_perplexity(feedback):\n",
    "    inputs = tokenizer(feedback, return_tensors='pt')\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs, labels=inputs['input_ids'])\n",
    "    loss = outputs.loss.item()\n",
    "    perplexity = torch.exp(torch.tensor(loss)).item()\n",
    "    inverse_perplexity = 1 / perplexity if perplexity != 0 else 0\n",
    "    return inverse_perplexity\n",
    "\n",
    "df['inverse_perplexity'] = df['feedback'].apply(calculate_inverse_perplexity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grammatical errors\n",
    "\n",
    "# Initialize the language tool\n",
    "tool = language_tool_python.LanguageTool('en-US')\n",
    "\n",
    "# Function to count grammatical errors\n",
    "def count_grammatical_errors(text):\n",
    "    matches = tool.check(text)\n",
    "    return len(matches)\n",
    "\n",
    "df['gr_count'] = df['feedback'].apply(count_grammatical_errors)\n",
    "df['gr_rate'] = df['gr_count'] / df['wc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>prompt</th>\n",
       "      <th>essay</th>\n",
       "      <th>excerpt</th>\n",
       "      <th>feedback</th>\n",
       "      <th>grade_level</th>\n",
       "      <th>domain1_score</th>\n",
       "      <th>type</th>\n",
       "      <th>wc</th>\n",
       "      <th>sc</th>\n",
       "      <th>fk</th>\n",
       "      <th>ttr</th>\n",
       "      <th>inverse_perplexity</th>\n",
       "      <th>gr_count</th>\n",
       "      <th>gr_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1206</td>\n",
       "      <td>More and more people use computers, but not ev...</td>\n",
       "      <td>Dear editor @ORGANIZATION2 the source, @CAPS1,...</td>\n",
       "      <td>I have noticed that many people have been spen...</td>\n",
       "      <td>Clear statement of your opinion. Good work.</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>persuasive</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>89.75</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.006574</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1206</td>\n",
       "      <td>More and more people use computers, but not ev...</td>\n",
       "      <td>Dear editor @ORGANIZATION2 the source, @CAPS1,...</td>\n",
       "      <td>imports</td>\n",
       "      <td>This word doesn't make sense here. Did you mea...</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>persuasive</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>99.73</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.010637</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1206</td>\n",
       "      <td>More and more people use computers, but not ev...</td>\n",
       "      <td>Dear editor @ORGANIZATION2 the source, @CAPS1,...</td>\n",
       "      <td>hygene</td>\n",
       "      <td>Go through this essay and check for minor spel...</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>persuasive</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>85.69</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.026086</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1206</td>\n",
       "      <td>More and more people use computers, but not ev...</td>\n",
       "      <td>Dear editor @ORGANIZATION2 the source, @CAPS1,...</td>\n",
       "      <td>These health risks are a concern,</td>\n",
       "      <td>Great explanation of your first point &amp; good t...</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>persuasive</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>67.76</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.004129</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1206</td>\n",
       "      <td>More and more people use computers, but not ev...</td>\n",
       "      <td>Dear editor @ORGANIZATION2 the source, @CAPS1,...</td>\n",
       "      <td>Safety is one @ORGANIZATION2 the most importan...</td>\n",
       "      <td>Solid example about how the internet can impac...</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>persuasive</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>44.41</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.010062</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   essay_id                                             prompt  \\\n",
       "0      1206  More and more people use computers, but not ev...   \n",
       "1      1206  More and more people use computers, but not ev...   \n",
       "2      1206  More and more people use computers, but not ev...   \n",
       "3      1206  More and more people use computers, but not ev...   \n",
       "4      1206  More and more people use computers, but not ev...   \n",
       "\n",
       "                                               essay  \\\n",
       "0  Dear editor @ORGANIZATION2 the source, @CAPS1,...   \n",
       "1  Dear editor @ORGANIZATION2 the source, @CAPS1,...   \n",
       "2  Dear editor @ORGANIZATION2 the source, @CAPS1,...   \n",
       "3  Dear editor @ORGANIZATION2 the source, @CAPS1,...   \n",
       "4  Dear editor @ORGANIZATION2 the source, @CAPS1,...   \n",
       "\n",
       "                                             excerpt  \\\n",
       "0  I have noticed that many people have been spen...   \n",
       "1                                            imports   \n",
       "2                                             hygene   \n",
       "3                  These health risks are a concern,   \n",
       "4  Safety is one @ORGANIZATION2 the most importan...   \n",
       "\n",
       "                                            feedback  grade_level  \\\n",
       "0        Clear statement of your opinion. Good work.            8   \n",
       "1  This word doesn't make sense here. Did you mea...            8   \n",
       "2  Go through this essay and check for minor spel...            8   \n",
       "3  Great explanation of your first point & good t...            8   \n",
       "4  Solid example about how the internet can impac...            8   \n",
       "\n",
       "   domain1_score        type  wc  sc     fk       ttr  inverse_perplexity  \\\n",
       "0             11  persuasive   7   2  89.75  0.888889            0.006574   \n",
       "1             11  persuasive  11   2  99.73  1.000000            0.010637   \n",
       "2             11  persuasive  22   2  85.69  0.880000            0.026086   \n",
       "3             11  persuasive  13   1  67.76  0.857143            0.004129   \n",
       "4             11  persuasive  10   1  44.41  1.000000            0.010062   \n",
       "\n",
       "   gr_count  gr_rate  \n",
       "0         0      0.0  \n",
       "1         0      0.0  \n",
       "2         0      0.0  \n",
       "3         0      0.0  \n",
       "4         0      0.0  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Specificity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Content Word Density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "def calculate_content_word_density(feedback):\n",
    "    tokens = word_tokenize(feedback)\n",
    "    pos_tags = pos_tag(tokens)\n",
    "    # Content words are nouns, verbs, adjectives, and adverbs\n",
    "    content_words = [word for word, pos in pos_tags if pos.startswith('NN') or pos.startswith('VB') or pos.startswith('JJ') or pos.startswith('RB')]\n",
    "    content_word_density = len(content_words) / len(tokens) if tokens else 0\n",
    "    \n",
    "    return content_word_density\n",
    "\n",
    "df['content_word_density'] = df['feedback'].apply(calculate_content_word_density)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uptake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def. uptake as overlap\n",
    "def calculate_uptake(excerpt, feedback):\n",
    "    # Tokenize both excerpt and feedback comment\n",
    "    excerpt_tokens = set(word_tokenize(excerpt.lower()))\n",
    "    feedback_tokens = set(word_tokenize(feedback.lower()))\n",
    "    \n",
    "    # Find common words\n",
    "    common_words = excerpt_tokens.intersection(feedback_tokens)\n",
    "    \n",
    "    # Calculate uptake as the ratio of common words to total words in the excerpt\n",
    "    uptake = len(common_words) / len(excerpt_tokens) if excerpt_tokens else 0\n",
    "    \n",
    "    return uptake\n",
    "\n",
    "# Apply the function to calculate uptake for each row\n",
    "df['uptake'] = df.apply(lambda row: calculate_uptake(row['excerpt'], row['feedback']), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Context Relevance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mxtan/.local/lib/python3.8/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# cosine similarity of embeddings\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "def get_embeddings(text):\n",
    "    inputs = tokenizer(text, return_tensors='pt', truncation=True, padding=True, max_length=512)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    embeddings = outputs.last_hidden_state.mean(dim=1).squeeze().numpy()\n",
    "    return embeddings\n",
    "\n",
    "# Function to calculate cosine similarity between embeddings\n",
    "def calculate_cosine_similarity(excerpt, feedback):\n",
    "    excerpt_embedding = get_embeddings(excerpt)\n",
    "    feedback_embedding = get_embeddings(feedback)\n",
    "    similarity = cosine_similarity([excerpt_embedding], [feedback_embedding])[0][0]\n",
    "    return similarity\n",
    "\n",
    "# Apply the function to calculate cosine similarity for each row\n",
    "df['cosine_similarity'] = df.apply(lambda row: calculate_cosine_similarity(row['excerpt'], row['feedback']), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantic Focus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pronouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_person_singular = {'i', 'me', 'my', 'mine'}\n",
    "second_person = {'you', 'your', 'yours'}\n",
    "first_person_plural = {'we', 'us', 'our', 'ours'}\n",
    "\n",
    "def count_pronouns(feedback, pronoun_set):\n",
    "    tokens = word_tokenize(feedback.lower())\n",
    "    pronoun_count = sum(1 for token in tokens if token in pronoun_set)\n",
    "    return pronoun_count\n",
    "\n",
    "df['pronoun_fps'] = df['feedback'].apply(lambda x: count_pronouns(x, first_person_singular))\n",
    "df['pronoun_sp'] = df['feedback'].apply(lambda x: count_pronouns(x, second_person))\n",
    "df['pronoun_fpp'] = df['feedback'].apply(lambda x: count_pronouns(x, first_person_plural))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "wh_words = {'what', 'where', 'when', 'which', 'who', 'whom', 'whose', 'why', 'how'}\n",
    "auxiliary_verbs = {'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'do', 'does', 'did', 'will', 'would', 'shall', 'should', 'can', 'could', 'may', 'might', 'must'}\n",
    "helping_verbs = {\"is\", \"am\", \"can\", \"are\", \"do\", \"does\"}\n",
    "\n",
    "def is_question(sentence):\n",
    "    tokens = word_tokenize(sentence)\n",
    "    return sentence.strip().endswith('?') or (tokens and (tokens[0] in wh_words or tokens[0] in helping_verbs))\n",
    "\n",
    "def count_wh_questions(feedback):\n",
    "    sentences = sent_tokenize(feedback.lower())\n",
    "    wh_question_count = sum(1 for sentence in sentences if is_question(sentence) and word_tokenize(sentence)[0] in wh_words)\n",
    "    return wh_question_count\n",
    "\n",
    "def count_yes_no_questions(feedback):\n",
    "    sentences = sent_tokenize(feedback.lower())\n",
    "    yes_no_question_count = sum(1 for sentence in sentences if is_question(sentence) and word_tokenize(sentence)[0] in auxiliary_verbs)\n",
    "    return yes_no_question_count\n",
    "\n",
    "df['wh_question_count'] = df['feedback'].apply(count_wh_questions)\n",
    "df['yes_no_question_count'] = df['feedback'].apply(count_yes_no_questions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()\n",
    "df.to_csv('human_meta_pt1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tid</th>\n",
       "      <th>grade</th>\n",
       "      <th>prompt</th>\n",
       "      <th>essay</th>\n",
       "      <th>essayid</th>\n",
       "      <th>excerpt</th>\n",
       "      <th>feedback</th>\n",
       "      <th>startidx</th>\n",
       "      <th>endidx</th>\n",
       "      <th>commentid</th>\n",
       "      <th>...</th>\n",
       "      <th>ttr</th>\n",
       "      <th>inverse_perplexity</th>\n",
       "      <th>content_word_density</th>\n",
       "      <th>uptake</th>\n",
       "      <th>cosine_similarity</th>\n",
       "      <th>pronoun_fps</th>\n",
       "      <th>pronoun_sp</th>\n",
       "      <th>pronoun_fpp</th>\n",
       "      <th>wh_question_count</th>\n",
       "      <th>yes_no_question_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rfQv3LPBikeoFIE1NyA3</td>\n",
       "      <td>ms</td>\n",
       "      <td>Some of your friends perform community service...</td>\n",
       "      <td>Dear Principal,\\n\\nI have heard you are having...</td>\n",
       "      <td>1CE6C10B9683</td>\n",
       "      <td>i</td>\n",
       "      <td>Capital and introductory phrase</td>\n",
       "      <td>255</td>\n",
       "      <td>258</td>\n",
       "      <td>1718398386391</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.507323</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rfQv3LPBikeoFIE1NyA3</td>\n",
       "      <td>ms</td>\n",
       "      <td>Some of your friends perform community service...</td>\n",
       "      <td>Dear Principal,\\n\\nI have heard you are having...</td>\n",
       "      <td>1CE6C10B9683</td>\n",
       "      <td>e a</td>\n",
       "      <td>Introductory phrase</td>\n",
       "      <td>548</td>\n",
       "      <td>551</td>\n",
       "      <td>1718398439880</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.654442</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rfQv3LPBikeoFIE1NyA3</td>\n",
       "      <td>ms</td>\n",
       "      <td>Some of your friends perform community service...</td>\n",
       "      <td>Dear Principal,\\n\\nI have heard you are having...</td>\n",
       "      <td>1CE6C10B9683</td>\n",
       "      <td>dyer</td>\n",
       "      <td>wrong word</td>\n",
       "      <td>1137</td>\n",
       "      <td>1141</td>\n",
       "      <td>1718398530582</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000170</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.683321</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rfQv3LPBikeoFIE1NyA3</td>\n",
       "      <td>ms</td>\n",
       "      <td>Some of your friends perform community service...</td>\n",
       "      <td>Dear Principal,\\n\\nI have heard you are having...</td>\n",
       "      <td>1CE6C10B9683</td>\n",
       "      <td>know it may sound funny but picking up trash ...</td>\n",
       "      <td>run-on sentence</td>\n",
       "      <td>1267</td>\n",
       "      <td>1487</td>\n",
       "      <td>1718398574934</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000780</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.426005</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rfQv3LPBikeoFIE1NyA3</td>\n",
       "      <td>ms</td>\n",
       "      <td>Some of your friends perform community service...</td>\n",
       "      <td>Dear Principal,\\n\\nI have heard you are having...</td>\n",
       "      <td>1CE6C10B9683</td>\n",
       "      <td>or example if one student did community servic...</td>\n",
       "      <td>Good example</td>\n",
       "      <td>791</td>\n",
       "      <td>875</td>\n",
       "      <td>1718398626223</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000219</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.460753</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    tid grade  \\\n",
       "0  rfQv3LPBikeoFIE1NyA3    ms   \n",
       "1  rfQv3LPBikeoFIE1NyA3    ms   \n",
       "2  rfQv3LPBikeoFIE1NyA3    ms   \n",
       "3  rfQv3LPBikeoFIE1NyA3    ms   \n",
       "4  rfQv3LPBikeoFIE1NyA3    ms   \n",
       "\n",
       "                                              prompt  \\\n",
       "0  Some of your friends perform community service...   \n",
       "1  Some of your friends perform community service...   \n",
       "2  Some of your friends perform community service...   \n",
       "3  Some of your friends perform community service...   \n",
       "4  Some of your friends perform community service...   \n",
       "\n",
       "                                               essay       essayid  \\\n",
       "0  Dear Principal,\\n\\nI have heard you are having...  1CE6C10B9683   \n",
       "1  Dear Principal,\\n\\nI have heard you are having...  1CE6C10B9683   \n",
       "2  Dear Principal,\\n\\nI have heard you are having...  1CE6C10B9683   \n",
       "3  Dear Principal,\\n\\nI have heard you are having...  1CE6C10B9683   \n",
       "4  Dear Principal,\\n\\nI have heard you are having...  1CE6C10B9683   \n",
       "\n",
       "                                             excerpt  \\\n",
       "0                                                 i    \n",
       "1                                                e a   \n",
       "2                                               dyer   \n",
       "3   know it may sound funny but picking up trash ...   \n",
       "4  or example if one student did community servic...   \n",
       "\n",
       "                          feedback  startidx  endidx      commentid  ...  ttr  \\\n",
       "0  Capital and introductory phrase       255     258  1718398386391  ...  1.0   \n",
       "1              Introductory phrase       548     551  1718398439880  ...  1.0   \n",
       "2                       wrong word      1137    1141  1718398530582  ...  1.0   \n",
       "3                  run-on sentence      1267    1487  1718398574934  ...  1.0   \n",
       "4                     Good example       791     875  1718398626223  ...  1.0   \n",
       "\n",
       "   inverse_perplexity  content_word_density  uptake cosine_similarity  \\\n",
       "0            0.000089                  0.75  0.0000          0.507323   \n",
       "1            0.000053                  1.00  0.0000          0.654442   \n",
       "2            0.000170                  1.00  0.0000          0.683321   \n",
       "3            0.000780                  1.00  0.0000          0.426005   \n",
       "4            0.000219                  1.00  0.0625          0.460753   \n",
       "\n",
       "   pronoun_fps  pronoun_sp  pronoun_fpp  wh_question_count  \\\n",
       "0            0           0            0                  0   \n",
       "1            0           0            0                  0   \n",
       "2            0           0            0                  0   \n",
       "3            0           0            0                  0   \n",
       "4            0           0            0                  0   \n",
       "\n",
       "   yes_no_question_count  \n",
       "0                      0  \n",
       "1                      0  \n",
       "2                      0  \n",
       "3                      0  \n",
       "4                      0  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "df = pd.read_csv('human_meta_pt1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['feedback'] = df['feedback'].astype(str)\n",
    "df['excerpt'] = df['excerpt'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non-Dialogic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mxtan/.local/lib/python3.8/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "  0%|          | 0/385 [00:00<?, ?it/s]/home/mxtan/.local/lib/python3.8/site-packages/transformers/pipelines/base.py:1157: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "100%|██████████| 385/385 [00:02<00:00, 139.63it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from transformers import pipeline\n",
    "pipe = pipeline(\"text-classification\", model=\"meiflwr/nondialogic_feedback\", device = 0)\n",
    "def get_dro(excerpt, feedback):\n",
    "    out = []\n",
    "    dro_out = pipe([{'text': feedback, 'text_pair': excerpt}])\n",
    "    if dro_out[0]['label'] == 'LABEL_1':\n",
    "        out.append(1)\n",
    "    else:\n",
    "        out.append(0)\n",
    "    return out\n",
    "\n",
    "tqdm.pandas()\n",
    "df['ND'] = df.progress_apply(lambda row: get_dro(row['excerpt'], row['feedback']), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non-Revision-Oriented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mxtan/.local/lib/python3.8/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "100%|██████████| 385/385 [00:11<00:00, 32.91it/s]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "pipe = pipeline(\"text-classification\", model=\"meiflwr/nonrevisionoriented_feedback\")\n",
    "def get_dro(excerpt, feedback):\n",
    "    out = []\n",
    "    dro_out = pipe([{'text': feedback, 'text_pair': excerpt}])\n",
    "    if dro_out[0]['label'] == 'LABEL_1':\n",
    "        out.append(1)\n",
    "    else:\n",
    "        out.append(0)\n",
    "    return out\n",
    "\n",
    "tqdm.pandas()\n",
    "df['NRO'] = df.progress_apply(lambda row: get_dro(row['excerpt'], row['feedback']), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pure Praise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mxtan/.local/lib/python3.8/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "100%|██████████| 385/385 [00:12<00:00, 30.64it/s]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "pipe = pipeline(\"text-classification\", model=\"meiflwr/praise_feedback\")\n",
    "def get_dro(excerpt, feedback):\n",
    "    out = []\n",
    "    dro_out = pipe([{'text': feedback, 'text_pair': excerpt}])\n",
    "    if dro_out[0]['label'] == 'LABEL_1':\n",
    "        out.append(1)\n",
    "    else:\n",
    "        out.append(0)\n",
    "    return out\n",
    "\n",
    "tqdm.pandas()\n",
    "df['PP'] = df.progress_apply(lambda row: get_dro(row['excerpt'], row['feedback']), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Power-Affirming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mxtan/.local/lib/python3.8/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "  0%|          | 0/385 [00:00<?, ?it/s]/home/mxtan/.local/lib/python3.8/site-packages/transformers/pipelines/base.py:1157: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "100%|██████████| 385/385 [00:02<00:00, 128.95it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "# Use a pipeline as a high-level helper\n",
    "from transformers import pipeline\n",
    "pipe = pipeline(\"text-classification\", model=\"meiflwr/power-affirming-feedback\", device = 0)\n",
    "def get_pa(excerpt, feedback):\n",
    "  reward = pipe([{'text': feedback, 'text_pair': excerpt}])\n",
    "  return reward[0]['score']\n",
    "\n",
    "tqdm.pandas()\n",
    "df['pa_mean'] = df.progress_apply(lambda row: get_pa(row['excerpt'], row['feedback']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5671552028748896"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['pa_mean'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mxtan/.local/lib/python3.8/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "100%|██████████| 385/385 [00:11<00:00, 32.42it/s]\n",
      "100%|██████████| 385/385 [00:11<00:00, 32.19it/s]\n",
      "100%|██████████| 385/385 [00:11<00:00, 33.14it/s]\n"
     ]
    }
   ],
   "source": [
    "# Use a pipeline as a high-level helper\n",
    "from transformers import pipeline\n",
    "pipe1 = pipeline(\"text-classification\", model=\"meiflwr/poweraffirming_feedback_skew1\")\n",
    "pipe2 = pipeline(\"text-classification\", model=\"meiflwr/poweraffirming_feedbak_skew2\")\n",
    "pipe3 = pipeline(\"text-classification\", model=\"meiflwr/poweraffirming_feedback_skew3\")\n",
    "\n",
    "def get_pa(excerpt, feedback, pipeline):\n",
    "  reward = pipeline([{'text': feedback, 'text_pair': excerpt}])\n",
    "  return reward[0]['score']\n",
    "\n",
    "tqdm.pandas()\n",
    "df['pa1'] = df.progress_apply(lambda row: get_pa(row['excerpt'], row['feedback'], pipe1), axis=1)\n",
    "df['pa2'] = df.progress_apply(lambda row: get_pa(row['excerpt'], row['feedback'], pipe2), axis=1)\n",
    "df['pa3'] = df.progress_apply(lambda row: get_pa(row['excerpt'], row['feedback'], pipe3), axis=1)\n",
    "\n",
    "# Calculate the variance of the pa-scores\n",
    "df['pa_var'] = df[['pa1', 'pa2', 'pa3']].var(axis=1)\n",
    "df['pa_mean2'] = df[['pa1', 'pa2', 'pa3']].mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5651473980445366\n",
      "0.5648816309191964\n",
      "0.5653255993669684\n",
      "0.565118209443567\n"
     ]
    }
   ],
   "source": [
    "print(df['pa1'].mean())\n",
    "print(df['pa2'].mean())\n",
    "print(df['pa3'].mean())\n",
    "print(df['pa_mean2'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('human_res_asap_meta.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
