{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install nltk pandas\n",
    "%pip install textstat\n",
    "%pip install transformers torch scikit-learn\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: language-tool-python in /home/mxtan/.local/lib/python3.8/site-packages (2.8)\n",
      "Requirement already satisfied: wheel in /usr/lib/python3/dist-packages (from language-tool-python) (0.34.2)\n",
      "Requirement already satisfied: pip in /usr/lib/python3/dist-packages (from language-tool-python) (20.0.2)\n",
      "Requirement already satisfied: requests in /usr/lib/python3/dist-packages (from language-tool-python) (2.22.0)\n",
      "Requirement already satisfied: tqdm in /home/mxtan/.local/lib/python3.8/site-packages (from language-tool-python) (4.66.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install language-tool-python\n",
    "import language_tool_python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('finetune_res_asap.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feedback word count\n",
    "df['feedback'] = df['feedback'].astype(str)\n",
    "df['wc'] = df['feedback'].apply(lambda x: len(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feedback sentence count\n",
    "def count_sentences(feedback):\n",
    "    sentences = sent_tokenize(feedback)\n",
    "    return len(sentences)\n",
    "\n",
    "df['sc'] = df['feedback'].apply(count_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fleisch kincaid\n",
    "import pandas as pd\n",
    "import textstat\n",
    "df['fk'] = df['feedback'].apply(textstat.flesch_reading_ease)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TTR\n",
    "import nltk\n",
    "def calculate_ttr(feedback):\n",
    "    tokens = word_tokenize(feedback)\n",
    "    unique_tokens = set(tokens)\n",
    "    ttr = len(unique_tokens) / len(tokens) if tokens else 0\n",
    "    return ttr\n",
    "\n",
    "df['ttr'] = df['feedback'].apply(calculate_ttr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fluency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mxtan/.local/lib/python3.8/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# inverse perplexity\n",
    "import torch\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "\n",
    "# Load pre-trained GPT-2 model and tokenizer\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "\n",
    "# Function to calculate inverse perplexity\n",
    "def calculate_inverse_perplexity(feedback):\n",
    "    inputs = tokenizer(feedback, return_tensors='pt')\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs, labels=inputs['input_ids'])\n",
    "    loss = outputs.loss.item()\n",
    "    perplexity = torch.exp(torch.tensor(loss)).item()\n",
    "    inverse_perplexity = 1 / perplexity if perplexity != 0 else 0\n",
    "    return inverse_perplexity\n",
    "\n",
    "df['inverse_perplexity'] = df['feedback'].apply(calculate_inverse_perplexity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grammatical errors\n",
    "\n",
    "# Initialize the language tool\n",
    "tool = language_tool_python.LanguageTool('en-US')\n",
    "\n",
    "# Function to count grammatical errors\n",
    "def count_grammatical_errors(text):\n",
    "    matches = tool.check(text)\n",
    "    return len(matches)\n",
    "\n",
    "df['gr_count'] = df['feedback'].apply(count_grammatical_errors)\n",
    "df['gr_rate'] = df['gr_count'] / df['wc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>prompt</th>\n",
       "      <th>essay</th>\n",
       "      <th>grade_level</th>\n",
       "      <th>domain1_score</th>\n",
       "      <th>type</th>\n",
       "      <th>input</th>\n",
       "      <th>predictions</th>\n",
       "      <th>extracted_content</th>\n",
       "      <th>excerpt</th>\n",
       "      <th>feedback</th>\n",
       "      <th>wc</th>\n",
       "      <th>sc</th>\n",
       "      <th>fk</th>\n",
       "      <th>ttr</th>\n",
       "      <th>inverse_perplexity</th>\n",
       "      <th>gr_count</th>\n",
       "      <th>gr_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1206</td>\n",
       "      <td>More and more people use computers, but not ev...</td>\n",
       "      <td>Dear editor @ORGANIZATION2 the source, @CAPS1,...</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>persuasive</td>\n",
       "      <td>### INSTRUCTIONS: You are my English teacher. ...</td>\n",
       "      <td>### INSTRUCTIONS: You are my English teacher. ...</td>\n",
       "      <td>***\"safety is on bigger issue\"---I agree, but ...</td>\n",
       "      <td>safety is on bigger issue</td>\n",
       "      <td>I agree, but what can we do to address the saf...</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>84.68</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.044490</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1206</td>\n",
       "      <td>More and more people use computers, but not ev...</td>\n",
       "      <td>Dear editor @ORGANIZATION2 the source, @CAPS1,...</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>persuasive</td>\n",
       "      <td>### INSTRUCTIONS: You are my English teacher. ...</td>\n",
       "      <td>### INSTRUCTIONS: You are my English teacher. ...</td>\n",
       "      <td>***\"safety is on bigger issue\"---I agree, but ...</td>\n",
       "      <td>The massive amounts @ORGANIZATION2 typing on t...</td>\n",
       "      <td>Good job providing evidence!</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>33.58</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000393</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1206</td>\n",
       "      <td>More and more people use computers, but not ev...</td>\n",
       "      <td>Dear editor @ORGANIZATION2 the source, @CAPS1,...</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>persuasive</td>\n",
       "      <td>### INSTRUCTIONS: You are my English teacher. ...</td>\n",
       "      <td>### INSTRUCTIONS: You are my English teacher. ...</td>\n",
       "      <td>***\"safety is on bigger issue\"---I agree, but ...</td>\n",
       "      <td>My bro, @PERSON2, had on assignment to do @DAT...</td>\n",
       "      <td>Brother, how could we strengthen our argument?...</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>44.91</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.016810</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1206</td>\n",
       "      <td>More and more people use computers, but not ev...</td>\n",
       "      <td>Dear editor @ORGANIZATION2 the source, @CAPS1,...</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>persuasive</td>\n",
       "      <td>### INSTRUCTIONS: You are my English teacher. ...</td>\n",
       "      <td>### INSTRUCTIONS: You are my English teacher. ...</td>\n",
       "      <td>***\"safety is on bigger issue\"---I agree, but ...</td>\n",
       "      <td>In closing, overusing your computer can cause ...</td>\n",
       "      <td>Excellent summary! Again, I would make sure to...</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>59.64</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.035278</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12191</td>\n",
       "      <td>Read \"Narciso Rodriguez\" by Narciso Rodriguez....</td>\n",
       "      <td>The mood of the memoir is appreciation. I thin...</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>litanalysis</td>\n",
       "      <td>### INSTRUCTIONS: You are my English teacher. ...</td>\n",
       "      <td>### INSTRUCTIONS: You are my English teacher. ...</td>\n",
       "      <td>***\" The mood of the memoir is appreciation. I...</td>\n",
       "      <td>The mood of the memoir is appreciation. I thin...</td>\n",
       "      <td>Good job identifying the mood of the memoir. R...</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>69.28</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.012918</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   essay_id                                             prompt  \\\n",
       "0      1206  More and more people use computers, but not ev...   \n",
       "1      1206  More and more people use computers, but not ev...   \n",
       "2      1206  More and more people use computers, but not ev...   \n",
       "3      1206  More and more people use computers, but not ev...   \n",
       "4     12191  Read \"Narciso Rodriguez\" by Narciso Rodriguez....   \n",
       "\n",
       "                                               essay  grade_level  \\\n",
       "0  Dear editor @ORGANIZATION2 the source, @CAPS1,...            8   \n",
       "1  Dear editor @ORGANIZATION2 the source, @CAPS1,...            8   \n",
       "2  Dear editor @ORGANIZATION2 the source, @CAPS1,...            8   \n",
       "3  Dear editor @ORGANIZATION2 the source, @CAPS1,...            8   \n",
       "4  The mood of the memoir is appreciation. I thin...            8   \n",
       "\n",
       "   domain1_score         type  \\\n",
       "0             11   persuasive   \n",
       "1             11   persuasive   \n",
       "2             11   persuasive   \n",
       "3             11   persuasive   \n",
       "4              3  litanalysis   \n",
       "\n",
       "                                               input  \\\n",
       "0  ### INSTRUCTIONS: You are my English teacher. ...   \n",
       "1  ### INSTRUCTIONS: You are my English teacher. ...   \n",
       "2  ### INSTRUCTIONS: You are my English teacher. ...   \n",
       "3  ### INSTRUCTIONS: You are my English teacher. ...   \n",
       "4  ### INSTRUCTIONS: You are my English teacher. ...   \n",
       "\n",
       "                                         predictions  \\\n",
       "0  ### INSTRUCTIONS: You are my English teacher. ...   \n",
       "1  ### INSTRUCTIONS: You are my English teacher. ...   \n",
       "2  ### INSTRUCTIONS: You are my English teacher. ...   \n",
       "3  ### INSTRUCTIONS: You are my English teacher. ...   \n",
       "4  ### INSTRUCTIONS: You are my English teacher. ...   \n",
       "\n",
       "                                   extracted_content  \\\n",
       "0  ***\"safety is on bigger issue\"---I agree, but ...   \n",
       "1  ***\"safety is on bigger issue\"---I agree, but ...   \n",
       "2  ***\"safety is on bigger issue\"---I agree, but ...   \n",
       "3  ***\"safety is on bigger issue\"---I agree, but ...   \n",
       "4  ***\" The mood of the memoir is appreciation. I...   \n",
       "\n",
       "                                             excerpt  \\\n",
       "0                          safety is on bigger issue   \n",
       "1  The massive amounts @ORGANIZATION2 typing on t...   \n",
       "2  My bro, @PERSON2, had on assignment to do @DAT...   \n",
       "3  In closing, overusing your computer can cause ...   \n",
       "4  The mood of the memoir is appreciation. I thin...   \n",
       "\n",
       "                                            feedback  wc  sc     fk       ttr  \\\n",
       "0  I agree, but what can we do to address the saf...  12   1  84.68  1.000000   \n",
       "1                       Good job providing evidence!   4   1  33.58  1.000000   \n",
       "2  Brother, how could we strengthen our argument?...  19   2  44.91  0.875000   \n",
       "3  Excellent summary! Again, I would make sure to...  20   2  59.64  0.913043   \n",
       "4  Good job identifying the mood of the memoir. R...  21   2  69.28  0.875000   \n",
       "\n",
       "   inverse_perplexity  gr_count  gr_rate  \n",
       "0            0.044490         0      0.0  \n",
       "1            0.000393         0      0.0  \n",
       "2            0.016810         0      0.0  \n",
       "3            0.035278         0      0.0  \n",
       "4            0.012918         0      0.0  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Specificity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Content Word Density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "def calculate_content_word_density(feedback):\n",
    "    tokens = word_tokenize(feedback)\n",
    "    pos_tags = pos_tag(tokens)\n",
    "    # Content words are nouns, verbs, adjectives, and adverbs\n",
    "    content_words = [word for word, pos in pos_tags if pos.startswith('NN') or pos.startswith('VB') or pos.startswith('JJ') or pos.startswith('RB')]\n",
    "    content_word_density = len(content_words) / len(tokens) if tokens else 0\n",
    "    \n",
    "    return content_word_density\n",
    "\n",
    "df['content_word_density'] = df['feedback'].apply(calculate_content_word_density)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uptake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def. uptake as overlap\n",
    "def calculate_uptake(excerpt, feedback):\n",
    "    # Tokenize both excerpt and feedback comment\n",
    "    excerpt_tokens = set(word_tokenize(excerpt.lower()))\n",
    "    feedback_tokens = set(word_tokenize(feedback.lower()))\n",
    "    \n",
    "    # Find common words\n",
    "    common_words = excerpt_tokens.intersection(feedback_tokens)\n",
    "    \n",
    "    # Calculate uptake as the ratio of common words to total words in the excerpt\n",
    "    uptake = len(common_words) / len(excerpt_tokens) if excerpt_tokens else 0\n",
    "    \n",
    "    return uptake\n",
    "\n",
    "# Apply the function to calculate uptake for each row\n",
    "df['uptake'] = df.apply(lambda row: calculate_uptake(row['excerpt'], row['feedback']), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Context Relevance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mxtan/.local/lib/python3.8/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# cosine similarity of embeddings\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "def get_embeddings(text):\n",
    "    inputs = tokenizer(text, return_tensors='pt', truncation=True, padding=True, max_length=512)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    embeddings = outputs.last_hidden_state.mean(dim=1).squeeze().numpy()\n",
    "    return embeddings\n",
    "\n",
    "# Function to calculate cosine similarity between embeddings\n",
    "def calculate_cosine_similarity(excerpt, feedback):\n",
    "    excerpt_embedding = get_embeddings(excerpt)\n",
    "    feedback_embedding = get_embeddings(feedback)\n",
    "    similarity = cosine_similarity([excerpt_embedding], [feedback_embedding])[0][0]\n",
    "    return similarity\n",
    "\n",
    "# Apply the function to calculate cosine similarity for each row\n",
    "df['cosine_similarity'] = df.apply(lambda row: calculate_cosine_similarity(row['excerpt'], row['feedback']), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantic Focus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pronouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_person_singular = {'i', 'me', 'my', 'mine'}\n",
    "second_person = {'you', 'your', 'yours'}\n",
    "first_person_plural = {'we', 'us', 'our', 'ours'}\n",
    "\n",
    "def count_pronouns(feedback, pronoun_set):\n",
    "    tokens = word_tokenize(feedback.lower())\n",
    "    pronoun_count = sum(1 for token in tokens if token in pronoun_set)\n",
    "    return pronoun_count\n",
    "\n",
    "df['pronoun_fps'] = df['feedback'].apply(lambda x: count_pronouns(x, first_person_singular))\n",
    "df['pronoun_sp'] = df['feedback'].apply(lambda x: count_pronouns(x, second_person))\n",
    "df['pronoun_fpp'] = df['feedback'].apply(lambda x: count_pronouns(x, first_person_plural))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "wh_words = {'what', 'where', 'when', 'which', 'who', 'whom', 'whose', 'why', 'how'}\n",
    "auxiliary_verbs = {'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'do', 'does', 'did', 'will', 'would', 'shall', 'should', 'can', 'could', 'may', 'might', 'must'}\n",
    "helping_verbs = {\"is\", \"am\", \"can\", \"are\", \"do\", \"does\"}\n",
    "\n",
    "def is_question(sentence):\n",
    "    tokens = word_tokenize(sentence)\n",
    "    return sentence.strip().endswith('?') or (tokens and (tokens[0] in wh_words or tokens[0] in helping_verbs))\n",
    "\n",
    "def count_wh_questions(feedback):\n",
    "    sentences = sent_tokenize(feedback.lower())\n",
    "    wh_question_count = sum(1 for sentence in sentences if is_question(sentence) and word_tokenize(sentence)[0] in wh_words)\n",
    "    return wh_question_count\n",
    "\n",
    "def count_yes_no_questions(feedback):\n",
    "    sentences = sent_tokenize(feedback.lower())\n",
    "    yes_no_question_count = sum(1 for sentence in sentences if is_question(sentence) and word_tokenize(sentence)[0] in auxiliary_verbs)\n",
    "    return yes_no_question_count\n",
    "\n",
    "df['wh_question_count'] = df['feedback'].apply(count_wh_questions)\n",
    "df['yes_no_question_count'] = df['feedback'].apply(count_yes_no_questions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()\n",
    "df.to_csv('human_meta_pt1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tid</th>\n",
       "      <th>grade</th>\n",
       "      <th>prompt</th>\n",
       "      <th>essay</th>\n",
       "      <th>essayid</th>\n",
       "      <th>excerpt</th>\n",
       "      <th>feedback</th>\n",
       "      <th>startidx</th>\n",
       "      <th>endidx</th>\n",
       "      <th>commentid</th>\n",
       "      <th>...</th>\n",
       "      <th>ttr</th>\n",
       "      <th>inverse_perplexity</th>\n",
       "      <th>content_word_density</th>\n",
       "      <th>uptake</th>\n",
       "      <th>cosine_similarity</th>\n",
       "      <th>pronoun_fps</th>\n",
       "      <th>pronoun_sp</th>\n",
       "      <th>pronoun_fpp</th>\n",
       "      <th>wh_question_count</th>\n",
       "      <th>yes_no_question_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rfQv3LPBikeoFIE1NyA3</td>\n",
       "      <td>ms</td>\n",
       "      <td>Some of your friends perform community service...</td>\n",
       "      <td>Dear Principal,\\n\\nI have heard you are having...</td>\n",
       "      <td>1CE6C10B9683</td>\n",
       "      <td>i</td>\n",
       "      <td>Capital and introductory phrase</td>\n",
       "      <td>255</td>\n",
       "      <td>258</td>\n",
       "      <td>1718398386391</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.507323</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rfQv3LPBikeoFIE1NyA3</td>\n",
       "      <td>ms</td>\n",
       "      <td>Some of your friends perform community service...</td>\n",
       "      <td>Dear Principal,\\n\\nI have heard you are having...</td>\n",
       "      <td>1CE6C10B9683</td>\n",
       "      <td>e a</td>\n",
       "      <td>Introductory phrase</td>\n",
       "      <td>548</td>\n",
       "      <td>551</td>\n",
       "      <td>1718398439880</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.654442</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rfQv3LPBikeoFIE1NyA3</td>\n",
       "      <td>ms</td>\n",
       "      <td>Some of your friends perform community service...</td>\n",
       "      <td>Dear Principal,\\n\\nI have heard you are having...</td>\n",
       "      <td>1CE6C10B9683</td>\n",
       "      <td>dyer</td>\n",
       "      <td>wrong word</td>\n",
       "      <td>1137</td>\n",
       "      <td>1141</td>\n",
       "      <td>1718398530582</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000170</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.683321</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rfQv3LPBikeoFIE1NyA3</td>\n",
       "      <td>ms</td>\n",
       "      <td>Some of your friends perform community service...</td>\n",
       "      <td>Dear Principal,\\n\\nI have heard you are having...</td>\n",
       "      <td>1CE6C10B9683</td>\n",
       "      <td>know it may sound funny but picking up trash ...</td>\n",
       "      <td>run-on sentence</td>\n",
       "      <td>1267</td>\n",
       "      <td>1487</td>\n",
       "      <td>1718398574934</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000780</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.426005</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rfQv3LPBikeoFIE1NyA3</td>\n",
       "      <td>ms</td>\n",
       "      <td>Some of your friends perform community service...</td>\n",
       "      <td>Dear Principal,\\n\\nI have heard you are having...</td>\n",
       "      <td>1CE6C10B9683</td>\n",
       "      <td>or example if one student did community servic...</td>\n",
       "      <td>Good example</td>\n",
       "      <td>791</td>\n",
       "      <td>875</td>\n",
       "      <td>1718398626223</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000219</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.460753</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    tid grade  \\\n",
       "0  rfQv3LPBikeoFIE1NyA3    ms   \n",
       "1  rfQv3LPBikeoFIE1NyA3    ms   \n",
       "2  rfQv3LPBikeoFIE1NyA3    ms   \n",
       "3  rfQv3LPBikeoFIE1NyA3    ms   \n",
       "4  rfQv3LPBikeoFIE1NyA3    ms   \n",
       "\n",
       "                                              prompt  \\\n",
       "0  Some of your friends perform community service...   \n",
       "1  Some of your friends perform community service...   \n",
       "2  Some of your friends perform community service...   \n",
       "3  Some of your friends perform community service...   \n",
       "4  Some of your friends perform community service...   \n",
       "\n",
       "                                               essay       essayid  \\\n",
       "0  Dear Principal,\\n\\nI have heard you are having...  1CE6C10B9683   \n",
       "1  Dear Principal,\\n\\nI have heard you are having...  1CE6C10B9683   \n",
       "2  Dear Principal,\\n\\nI have heard you are having...  1CE6C10B9683   \n",
       "3  Dear Principal,\\n\\nI have heard you are having...  1CE6C10B9683   \n",
       "4  Dear Principal,\\n\\nI have heard you are having...  1CE6C10B9683   \n",
       "\n",
       "                                             excerpt  \\\n",
       "0                                                 i    \n",
       "1                                                e a   \n",
       "2                                               dyer   \n",
       "3   know it may sound funny but picking up trash ...   \n",
       "4  or example if one student did community servic...   \n",
       "\n",
       "                          feedback  startidx  endidx      commentid  ...  ttr  \\\n",
       "0  Capital and introductory phrase       255     258  1718398386391  ...  1.0   \n",
       "1              Introductory phrase       548     551  1718398439880  ...  1.0   \n",
       "2                       wrong word      1137    1141  1718398530582  ...  1.0   \n",
       "3                  run-on sentence      1267    1487  1718398574934  ...  1.0   \n",
       "4                     Good example       791     875  1718398626223  ...  1.0   \n",
       "\n",
       "   inverse_perplexity  content_word_density  uptake cosine_similarity  \\\n",
       "0            0.000089                  0.75  0.0000          0.507323   \n",
       "1            0.000053                  1.00  0.0000          0.654442   \n",
       "2            0.000170                  1.00  0.0000          0.683321   \n",
       "3            0.000780                  1.00  0.0000          0.426005   \n",
       "4            0.000219                  1.00  0.0625          0.460753   \n",
       "\n",
       "   pronoun_fps  pronoun_sp  pronoun_fpp  wh_question_count  \\\n",
       "0            0           0            0                  0   \n",
       "1            0           0            0                  0   \n",
       "2            0           0            0                  0   \n",
       "3            0           0            0                  0   \n",
       "4            0           0            0                  0   \n",
       "\n",
       "   yes_no_question_count  \n",
       "0                      0  \n",
       "1                      0  \n",
       "2                      0  \n",
       "3                      0  \n",
       "4                      0  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "df = pd.read_csv('human_meta_pt1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['feedback'] = df['feedback'].astype(str)\n",
    "df['excerpt'] = df['excerpt'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non-Dialogic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mxtan/.local/lib/python3.8/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "  0%|          | 0/200 [00:00<?, ?it/s]/home/mxtan/.local/lib/python3.8/site-packages/transformers/pipelines/base.py:1157: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "100%|██████████| 200/200 [00:01<00:00, 134.35it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from transformers import pipeline\n",
    "pipe = pipeline(\"text-classification\", model=\"meiflwr/nondialogic_feedback\", device = 0)\n",
    "def get_dro(excerpt, feedback):\n",
    "    out = []\n",
    "    dro_out = pipe([{'text': feedback, 'text_pair': excerpt}])\n",
    "    if dro_out[0]['label'] == 'LABEL_1':\n",
    "        out.append(1)\n",
    "    else:\n",
    "        out.append(0)\n",
    "    return out\n",
    "\n",
    "tqdm.pandas()\n",
    "df['ND'] = df.progress_apply(lambda row: get_dro(row['excerpt'], row['feedback']), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non-Revision-Oriented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mxtan/.local/lib/python3.8/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "100%|██████████| 200/200 [00:05<00:00, 33.37it/s]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "pipe = pipeline(\"text-classification\", model=\"meiflwr/nonrevisionoriented_feedback\")\n",
    "def get_dro(excerpt, feedback):\n",
    "    out = []\n",
    "    dro_out = pipe([{'text': feedback, 'text_pair': excerpt}])\n",
    "    if dro_out[0]['label'] == 'LABEL_1':\n",
    "        out.append(1)\n",
    "    else:\n",
    "        out.append(0)\n",
    "    return out\n",
    "\n",
    "tqdm.pandas()\n",
    "df['NRO'] = df.progress_apply(lambda row: get_dro(row['excerpt'], row['feedback']), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pure Praise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mxtan/.local/lib/python3.8/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "100%|██████████| 200/200 [00:06<00:00, 31.66it/s]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "pipe = pipeline(\"text-classification\", model=\"meiflwr/praise_feedback\")\n",
    "def get_dro(excerpt, feedback):\n",
    "    out = []\n",
    "    dro_out = pipe([{'text': feedback, 'text_pair': excerpt}])\n",
    "    if dro_out[0]['label'] == 'LABEL_1':\n",
    "        out.append(1)\n",
    "    else:\n",
    "        out.append(0)\n",
    "    return out\n",
    "\n",
    "tqdm.pandas()\n",
    "df['PP'] = df.progress_apply(lambda row: get_dro(row['excerpt'], row['feedback']), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Power-Affirming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mxtan/.local/lib/python3.8/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "  0%|          | 0/200 [00:00<?, ?it/s]/home/mxtan/.local/lib/python3.8/site-packages/transformers/pipelines/base.py:1157: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "100%|██████████| 200/200 [00:01<00:00, 134.35it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "# Use a pipeline as a high-level helper\n",
    "from transformers import pipeline\n",
    "pipe = pipeline(\"text-classification\", model=\"meiflwr/power-affirming-feedback\", device = 0)\n",
    "def get_pa(excerpt, feedback):\n",
    "  reward = pipe([{'text': feedback, 'text_pair': excerpt}])\n",
    "  return reward[0]['score']\n",
    "\n",
    "tqdm.pandas()\n",
    "df['pa_mean'] = df.progress_apply(lambda row: get_pa(row['excerpt'], row['feedback']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5849784334003926"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['pa_mean'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mxtan/.local/lib/python3.8/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "100%|██████████| 200/200 [00:06<00:00, 32.01it/s]\n",
      "100%|██████████| 200/200 [00:06<00:00, 31.95it/s]\n",
      "100%|██████████| 200/200 [00:05<00:00, 33.54it/s]\n"
     ]
    }
   ],
   "source": [
    "# Use a pipeline as a high-level helper\n",
    "from transformers import pipeline\n",
    "pipe1 = pipeline(\"text-classification\", model=\"meiflwr/poweraffirming_feedback_skew1\")\n",
    "pipe2 = pipeline(\"text-classification\", model=\"meiflwr/poweraffirming_feedbak_skew2\")\n",
    "pipe3 = pipeline(\"text-classification\", model=\"meiflwr/poweraffirming_feedback_skew3\")\n",
    "\n",
    "def get_pa(excerpt, feedback, pipeline):\n",
    "  reward = pipeline([{'text': feedback, 'text_pair': excerpt}])\n",
    "  return reward[0]['score']\n",
    "\n",
    "tqdm.pandas()\n",
    "df['pa1'] = df.progress_apply(lambda row: get_pa(row['excerpt'], row['feedback'], pipe1), axis=1)\n",
    "df['pa2'] = df.progress_apply(lambda row: get_pa(row['excerpt'], row['feedback'], pipe2), axis=1)\n",
    "df['pa3'] = df.progress_apply(lambda row: get_pa(row['excerpt'], row['feedback'], pipe3), axis=1)\n",
    "\n",
    "# Calculate the variance of the pa-scores\n",
    "df['pa_var'] = df[['pa1', 'pa2', 'pa3']].var(axis=1)\n",
    "df['pa_mean2'] = df[['pa1', 'pa2', 'pa3']].mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5847966998815537\n",
      "0.584222854077816\n",
      "0.5793448173999787\n",
      "0.5827881237864494\n"
     ]
    }
   ],
   "source": [
    "print(df['pa1'].mean())\n",
    "print(df['pa2'].mean())\n",
    "print(df['pa3'].mean())\n",
    "print(df['pa_mean2'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('finetune_res_asap_meta.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
