{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /Applications/anaconda3/envs/cs224n/lib/python3.7/site-packages (3.6.5)\n",
      "Requirement already satisfied: pandas in /Applications/anaconda3/envs/cs224n/lib/python3.7/site-packages (1.3.5)\n",
      "Requirement already satisfied: click in /Applications/anaconda3/envs/cs224n/lib/python3.7/site-packages (from nltk) (8.0.3)\n",
      "Requirement already satisfied: joblib in /Applications/anaconda3/envs/cs224n/lib/python3.7/site-packages (from nltk) (1.1.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Applications/anaconda3/envs/cs224n/lib/python3.7/site-packages (from nltk) (2021.8.3)\n",
      "Requirement already satisfied: tqdm in /Applications/anaconda3/envs/cs224n/lib/python3.7/site-packages (from nltk) (4.66.4)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /Applications/anaconda3/envs/cs224n/lib/python3.7/site-packages (from pandas) (1.21.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /Applications/anaconda3/envs/cs224n/lib/python3.7/site-packages (from pandas) (2021.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /Applications/anaconda3/envs/cs224n/lib/python3.7/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /Applications/anaconda3/envs/cs224n/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas) (1.16.0)\n",
      "Requirement already satisfied: importlib-metadata in /Applications/anaconda3/envs/cs224n/lib/python3.7/site-packages (from click->nltk) (4.8.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /Applications/anaconda3/envs/cs224n/lib/python3.7/site-packages (from importlib-metadata->click->nltk) (3.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /Applications/anaconda3/envs/cs224n/lib/python3.7/site-packages (from importlib-metadata->click->nltk) (4.7.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: textstat in /Applications/anaconda3/envs/cs224n/lib/python3.7/site-packages (0.7.3)\n",
      "Requirement already satisfied: pyphen in /Applications/anaconda3/envs/cs224n/lib/python3.7/site-packages (from textstat) (0.14.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: transformers in /Applications/anaconda3/envs/cs224n/lib/python3.7/site-packages (4.30.2)\n",
      "Requirement already satisfied: torch in /Applications/anaconda3/envs/cs224n/lib/python3.7/site-packages (1.13.1)\n",
      "Requirement already satisfied: scikit-learn in /Applications/anaconda3/envs/cs224n/lib/python3.7/site-packages (1.0.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /Applications/anaconda3/envs/cs224n/lib/python3.7/site-packages (from transformers) (0.16.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /Applications/anaconda3/envs/cs224n/lib/python3.7/site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: filelock in /Applications/anaconda3/envs/cs224n/lib/python3.7/site-packages (from transformers) (3.12.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Applications/anaconda3/envs/cs224n/lib/python3.7/site-packages (from transformers) (4.66.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Applications/anaconda3/envs/cs224n/lib/python3.7/site-packages (from transformers) (2021.8.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /Applications/anaconda3/envs/cs224n/lib/python3.7/site-packages (from transformers) (1.21.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Applications/anaconda3/envs/cs224n/lib/python3.7/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: requests in /Applications/anaconda3/envs/cs224n/lib/python3.7/site-packages (from transformers) (2.26.0)\n",
      "Requirement already satisfied: importlib-metadata in /Applications/anaconda3/envs/cs224n/lib/python3.7/site-packages (from transformers) (4.8.2)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /Applications/anaconda3/envs/cs224n/lib/python3.7/site-packages (from transformers) (0.4.3)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /Applications/anaconda3/envs/cs224n/lib/python3.7/site-packages (from transformers) (0.13.3)\n",
      "Requirement already satisfied: typing-extensions in /Applications/anaconda3/envs/cs224n/lib/python3.7/site-packages (from torch) (4.7.1)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /Applications/anaconda3/envs/cs224n/lib/python3.7/site-packages (from scikit-learn) (1.7.1)\n",
      "Requirement already satisfied: joblib>=0.11 in /Applications/anaconda3/envs/cs224n/lib/python3.7/site-packages (from scikit-learn) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Applications/anaconda3/envs/cs224n/lib/python3.7/site-packages (from scikit-learn) (2.2.0)\n",
      "Requirement already satisfied: fsspec in /Applications/anaconda3/envs/cs224n/lib/python3.7/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.1.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Applications/anaconda3/envs/cs224n/lib/python3.7/site-packages (from packaging>=20.0->transformers) (3.0.4)\n",
      "Requirement already satisfied: zipp>=0.5 in /Applications/anaconda3/envs/cs224n/lib/python3.7/site-packages (from importlib-metadata->transformers) (3.6.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Applications/anaconda3/envs/cs224n/lib/python3.7/site-packages (from requests->transformers) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Applications/anaconda3/envs/cs224n/lib/python3.7/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Applications/anaconda3/envs/cs224n/lib/python3.7/site-packages (from requests->transformers) (2020.6.20)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Applications/anaconda3/envs/cs224n/lib/python3.7/site-packages (from requests->transformers) (1.26.7)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/meitan/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package punkt to /Users/meitan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pip install nltk pandas\n",
    "%pip install textstat\n",
    "%pip install transformers torch scikit-learn\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting language-tool-python\n",
      "  Downloading language_tool_python-2.8-py3-none-any.whl (35 kB)\n",
      "Requirement already satisfied: requests in /Applications/anaconda3/envs/cs224n/lib/python3.7/site-packages (from language-tool-python) (2.26.0)\n",
      "Requirement already satisfied: tqdm in /Applications/anaconda3/envs/cs224n/lib/python3.7/site-packages (from language-tool-python) (4.66.4)\n",
      "Requirement already satisfied: pip in /Applications/anaconda3/envs/cs224n/lib/python3.7/site-packages (from language-tool-python) (21.2.2)\n",
      "Requirement already satisfied: wheel in /Applications/anaconda3/envs/cs224n/lib/python3.7/site-packages (from language-tool-python) (0.37.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Applications/anaconda3/envs/cs224n/lib/python3.7/site-packages (from requests->language-tool-python) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Applications/anaconda3/envs/cs224n/lib/python3.7/site-packages (from requests->language-tool-python) (1.26.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Applications/anaconda3/envs/cs224n/lib/python3.7/site-packages (from requests->language-tool-python) (2020.6.20)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Applications/anaconda3/envs/cs224n/lib/python3.7/site-packages (from requests->language-tool-python) (2.0.4)\n",
      "Installing collected packages: language-tool-python\n",
      "Successfully installed language-tool-python-2.8\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install language-tool-python\n",
    "import language_tool_python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('nwp_feedback_7_25.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feedback word count\n",
    "df['feedback'] = df['feedback'].astype(str)\n",
    "df['wc'] = df['feedback'].apply(lambda x: len(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feedback sentence count\n",
    "def count_sentences(feedback):\n",
    "    sentences = sent_tokenize(feedback)\n",
    "    return len(sentences)\n",
    "\n",
    "df['sc'] = df['feedback'].apply(count_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fleisch kincaid\n",
    "import pandas as pd\n",
    "import textstat\n",
    "df['fk'] = df['feedback'].apply(textstat.flesch_reading_ease)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TTR\n",
    "import nltk\n",
    "def calculate_ttr(feedback):\n",
    "    tokens = word_tokenize(feedback)\n",
    "    unique_tokens = set(tokens)\n",
    "    ttr = len(unique_tokens) / len(tokens) if tokens else 0\n",
    "    return ttr\n",
    "\n",
    "df['ttr'] = df['feedback'].apply(calculate_ttr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fluency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inverse perplexity\n",
    "import torch\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "\n",
    "# Load pre-trained GPT-2 model and tokenizer\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "\n",
    "# Function to calculate inverse perplexity\n",
    "def calculate_inverse_perplexity(feedback):\n",
    "    inputs = tokenizer(feedback, return_tensors='pt')\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs, labels=inputs['input_ids'])\n",
    "    loss = outputs.loss.item()\n",
    "    perplexity = torch.exp(torch.tensor(loss)).item()\n",
    "    inverse_perplexity = 1 / perplexity if perplexity != 0 else 0\n",
    "    return inverse_perplexity\n",
    "\n",
    "df['inverse_perplexity'] = df['feedback'].apply(calculate_inverse_perplexity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading LanguageTool 6.4: 100%|██████████| 246M/246M [00:05<00:00, 45.8MB/s] \n",
      "Unzipping /var/folders/y8/f8p3n2q93s17hqbx5z1j26000000gn/T/tmphlw63ale.zip to /Users/meitan/.cache/language_tool_python.\n",
      "Downloaded https://www.languagetool.org/download/LanguageTool-6.4.zip to /Users/meitan/.cache/language_tool_python.\n"
     ]
    }
   ],
   "source": [
    "# grammatical errors\n",
    "\n",
    "# Initialize the language tool\n",
    "tool = language_tool_python.LanguageTool('en-US')\n",
    "\n",
    "# Function to count grammatical errors\n",
    "def count_grammatical_errors(text):\n",
    "    matches = tool.check(text)\n",
    "    return len(matches)\n",
    "\n",
    "df['gr_count'] = df['feedback'].apply(count_grammatical_errors)\n",
    "df['gr_rate'] = df['gr_count'] / df['wc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tid</th>\n",
       "      <th>grade</th>\n",
       "      <th>prompt</th>\n",
       "      <th>essay</th>\n",
       "      <th>essayid</th>\n",
       "      <th>excerpt</th>\n",
       "      <th>feedback</th>\n",
       "      <th>startidx</th>\n",
       "      <th>endidx</th>\n",
       "      <th>commentid</th>\n",
       "      <th>...</th>\n",
       "      <th>gender</th>\n",
       "      <th>race</th>\n",
       "      <th>ed</th>\n",
       "      <th>ds</th>\n",
       "      <th>ell</th>\n",
       "      <th>sc</th>\n",
       "      <th>fk</th>\n",
       "      <th>ttr</th>\n",
       "      <th>gr_count</th>\n",
       "      <th>gr_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rfQv3LPBikeoFIE1NyA3</td>\n",
       "      <td>ms</td>\n",
       "      <td>Some of your friends perform community service...</td>\n",
       "      <td>Dear Principal,\\n\\nI have heard you are having...</td>\n",
       "      <td>1CE6C10B9683</td>\n",
       "      <td>i</td>\n",
       "      <td>Capital and introductory phrase</td>\n",
       "      <td>255</td>\n",
       "      <td>258</td>\n",
       "      <td>1718398386391</td>\n",
       "      <td>...</td>\n",
       "      <td>F</td>\n",
       "      <td>White</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-8.73</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rfQv3LPBikeoFIE1NyA3</td>\n",
       "      <td>ms</td>\n",
       "      <td>Some of your friends perform community service...</td>\n",
       "      <td>Dear Principal,\\n\\nI have heard you are having...</td>\n",
       "      <td>1CE6C10B9683</td>\n",
       "      <td>e a</td>\n",
       "      <td>Introductory phrase</td>\n",
       "      <td>548</td>\n",
       "      <td>551</td>\n",
       "      <td>1718398439880</td>\n",
       "      <td>...</td>\n",
       "      <td>F</td>\n",
       "      <td>White</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-49.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rfQv3LPBikeoFIE1NyA3</td>\n",
       "      <td>ms</td>\n",
       "      <td>Some of your friends perform community service...</td>\n",
       "      <td>Dear Principal,\\n\\nI have heard you are having...</td>\n",
       "      <td>1CE6C10B9683</td>\n",
       "      <td>dyer</td>\n",
       "      <td>wrong word</td>\n",
       "      <td>1137</td>\n",
       "      <td>1141</td>\n",
       "      <td>1718398530582</td>\n",
       "      <td>...</td>\n",
       "      <td>F</td>\n",
       "      <td>White</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>120.21</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rfQv3LPBikeoFIE1NyA3</td>\n",
       "      <td>ms</td>\n",
       "      <td>Some of your friends perform community service...</td>\n",
       "      <td>Dear Principal,\\n\\nI have heard you are having...</td>\n",
       "      <td>1CE6C10B9683</td>\n",
       "      <td>know it may sound funny but picking up trash ...</td>\n",
       "      <td>run-on sentence</td>\n",
       "      <td>1267</td>\n",
       "      <td>1487</td>\n",
       "      <td>1718398574934</td>\n",
       "      <td>...</td>\n",
       "      <td>F</td>\n",
       "      <td>White</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>77.91</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rfQv3LPBikeoFIE1NyA3</td>\n",
       "      <td>ms</td>\n",
       "      <td>Some of your friends perform community service...</td>\n",
       "      <td>Dear Principal,\\n\\nI have heard you are having...</td>\n",
       "      <td>1CE6C10B9683</td>\n",
       "      <td>or example if one student did community servic...</td>\n",
       "      <td>Good example</td>\n",
       "      <td>791</td>\n",
       "      <td>875</td>\n",
       "      <td>1718398626223</td>\n",
       "      <td>...</td>\n",
       "      <td>F</td>\n",
       "      <td>White</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>35.61</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    tid grade  \\\n",
       "0  rfQv3LPBikeoFIE1NyA3    ms   \n",
       "1  rfQv3LPBikeoFIE1NyA3    ms   \n",
       "2  rfQv3LPBikeoFIE1NyA3    ms   \n",
       "3  rfQv3LPBikeoFIE1NyA3    ms   \n",
       "4  rfQv3LPBikeoFIE1NyA3    ms   \n",
       "\n",
       "                                              prompt  \\\n",
       "0  Some of your friends perform community service...   \n",
       "1  Some of your friends perform community service...   \n",
       "2  Some of your friends perform community service...   \n",
       "3  Some of your friends perform community service...   \n",
       "4  Some of your friends perform community service...   \n",
       "\n",
       "                                               essay       essayid  \\\n",
       "0  Dear Principal,\\n\\nI have heard you are having...  1CE6C10B9683   \n",
       "1  Dear Principal,\\n\\nI have heard you are having...  1CE6C10B9683   \n",
       "2  Dear Principal,\\n\\nI have heard you are having...  1CE6C10B9683   \n",
       "3  Dear Principal,\\n\\nI have heard you are having...  1CE6C10B9683   \n",
       "4  Dear Principal,\\n\\nI have heard you are having...  1CE6C10B9683   \n",
       "\n",
       "                                             excerpt  \\\n",
       "0                                                 i    \n",
       "1                                                e a   \n",
       "2                                               dyer   \n",
       "3   know it may sound funny but picking up trash ...   \n",
       "4  or example if one student did community servic...   \n",
       "\n",
       "                          feedback  startidx  endidx      commentid  ...  \\\n",
       "0  Capital and introductory phrase       255     258  1718398386391  ...   \n",
       "1              Introductory phrase       548     551  1718398439880  ...   \n",
       "2                       wrong word      1137    1141  1718398530582  ...   \n",
       "3                  run-on sentence      1267    1487  1718398574934  ...   \n",
       "4                     Good example       791     875  1718398626223  ...   \n",
       "\n",
       "  gender   race  ed ds ell  sc      fk  ttr  gr_count  gr_rate  \n",
       "0      F  White   0  0   0   1   -8.73  1.0         0      0.0  \n",
       "1      F  White   0  0   0   1  -49.00  1.0         0      0.0  \n",
       "2      F  White   0  0   0   1  120.21  1.0         1      0.5  \n",
       "3      F  White   0  0   0   1   77.91  1.0         1      0.5  \n",
       "4      F  White   0  0   0   1   35.61  1.0         0      0.0  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Specificity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Content Word Density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "def calculate_content_word_density(feedback):\n",
    "    tokens = word_tokenize(feedback)\n",
    "    pos_tags = pos_tag(tokens)\n",
    "    # Content words are nouns, verbs, adjectives, and adverbs\n",
    "    content_words = [word for word, pos in pos_tags if pos.startswith('NN') or pos.startswith('VB') or pos.startswith('JJ') or pos.startswith('RB')]\n",
    "    content_word_density = len(content_words) / len(tokens) if tokens else 0\n",
    "    \n",
    "    return content_word_density\n",
    "\n",
    "df['content_word_density'] = df['feedback'].apply(calculate_content_word_density)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uptake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def. uptake as overlap\n",
    "def calculate_uptake(excerpt, feedback):\n",
    "    # Tokenize both excerpt and feedback comment\n",
    "    excerpt_tokens = set(word_tokenize(excerpt.lower()))\n",
    "    feedback_tokens = set(word_tokenize(feedback.lower()))\n",
    "    \n",
    "    # Find common words\n",
    "    common_words = excerpt_tokens.intersection(feedback_tokens)\n",
    "    \n",
    "    # Calculate uptake as the ratio of common words to total words in the excerpt\n",
    "    uptake = len(common_words) / len(excerpt_tokens) if excerpt_tokens else 0\n",
    "    \n",
    "    return uptake\n",
    "\n",
    "# Apply the function to calculate uptake for each row\n",
    "df['uptake'] = df.apply(lambda row: calculate_uptake(row['excerpt'], row['feedback']), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Context Relevance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# cosine similarity of embeddings\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "def get_embeddings(text):\n",
    "    inputs = tokenizer(text, return_tensors='pt', truncation=True, padding=True, max_length=512)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    embeddings = outputs.last_hidden_state.mean(dim=1).squeeze().numpy()\n",
    "    return embeddings\n",
    "\n",
    "# Function to calculate cosine similarity between embeddings\n",
    "def calculate_cosine_similarity(excerpt, feedback):\n",
    "    excerpt_embedding = get_embeddings(excerpt)\n",
    "    feedback_embedding = get_embeddings(feedback)\n",
    "    similarity = cosine_similarity([excerpt_embedding], [feedback_embedding])[0][0]\n",
    "    return similarity\n",
    "\n",
    "# Apply the function to calculate cosine similarity for each row\n",
    "df['cosine_similarity'] = df.apply(lambda row: calculate_cosine_similarity(row['excerpt'], row['feedback']), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantic Focus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pronouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_person_singular = {'i', 'me', 'my', 'mine'}\n",
    "second_person = {'you', 'your', 'yours'}\n",
    "first_person_plural = {'we', 'us', 'our', 'ours'}\n",
    "\n",
    "def count_pronouns(feedback, pronoun_set):\n",
    "    tokens = word_tokenize(feedback.lower())\n",
    "    pronoun_count = sum(1 for token in tokens if token in pronoun_set)\n",
    "    return pronoun_count\n",
    "\n",
    "df['pronoun_fps'] = df['feedback'].apply(lambda x: count_pronouns(x, first_person_singular))\n",
    "df['pronoun_sp'] = df['feedback'].apply(lambda x: count_pronouns(x, second_person))\n",
    "df['pronoun_fpp'] = df['feedback'].apply(lambda x: count_pronouns(x, first_person_plural))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "wh_words = {'what', 'where', 'when', 'which', 'who', 'whom', 'whose', 'why', 'how'}\n",
    "auxiliary_verbs = {'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'do', 'does', 'did', 'will', 'would', 'shall', 'should', 'can', 'could', 'may', 'might', 'must'}\n",
    "helping_verbs = {\"is\", \"am\", \"can\", \"are\", \"do\", \"does\"}\n",
    "\n",
    "def is_question(sentence):\n",
    "    tokens = word_tokenize(sentence)\n",
    "    return sentence.strip().endswith('?') or (tokens and (tokens[0] in wh_words or tokens[0] in helping_verbs))\n",
    "\n",
    "def count_wh_questions(feedback):\n",
    "    sentences = sent_tokenize(feedback.lower())\n",
    "    wh_question_count = sum(1 for sentence in sentences if is_question(sentence) and word_tokenize(sentence)[0] in wh_words)\n",
    "    return wh_question_count\n",
    "\n",
    "def count_yes_no_questions(feedback):\n",
    "    sentences = sent_tokenize(feedback.lower())\n",
    "    yes_no_question_count = sum(1 for sentence in sentences if is_question(sentence) and word_tokenize(sentence)[0] in auxiliary_verbs)\n",
    "    return yes_no_question_count\n",
    "\n",
    "df['wh_question_count'] = df['feedback'].apply(count_wh_questions)\n",
    "df['yes_no_question_count'] = df['feedback'].apply(count_yes_no_questions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()\n",
    "df.to_csv('nwp_pt1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tid</th>\n",
       "      <th>grade</th>\n",
       "      <th>prompt</th>\n",
       "      <th>essay</th>\n",
       "      <th>essayid</th>\n",
       "      <th>excerpt</th>\n",
       "      <th>feedback</th>\n",
       "      <th>startidx</th>\n",
       "      <th>endidx</th>\n",
       "      <th>commentid</th>\n",
       "      <th>...</th>\n",
       "      <th>gr_count</th>\n",
       "      <th>gr_rate</th>\n",
       "      <th>content_word_density</th>\n",
       "      <th>uptake</th>\n",
       "      <th>cosine_similarity</th>\n",
       "      <th>pronoun_fps</th>\n",
       "      <th>pronoun_sp</th>\n",
       "      <th>pronoun_fpp</th>\n",
       "      <th>wh_question_count</th>\n",
       "      <th>yes_no_question_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rfQv3LPBikeoFIE1NyA3</td>\n",
       "      <td>ms</td>\n",
       "      <td>Some of your friends perform community service...</td>\n",
       "      <td>Dear Principal,\\n\\nI have heard you are having...</td>\n",
       "      <td>1CE6C10B9683</td>\n",
       "      <td>i</td>\n",
       "      <td>Capital and introductory phrase</td>\n",
       "      <td>255</td>\n",
       "      <td>258</td>\n",
       "      <td>1718398386391</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.507323</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rfQv3LPBikeoFIE1NyA3</td>\n",
       "      <td>ms</td>\n",
       "      <td>Some of your friends perform community service...</td>\n",
       "      <td>Dear Principal,\\n\\nI have heard you are having...</td>\n",
       "      <td>1CE6C10B9683</td>\n",
       "      <td>e a</td>\n",
       "      <td>Introductory phrase</td>\n",
       "      <td>548</td>\n",
       "      <td>551</td>\n",
       "      <td>1718398439880</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.654442</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rfQv3LPBikeoFIE1NyA3</td>\n",
       "      <td>ms</td>\n",
       "      <td>Some of your friends perform community service...</td>\n",
       "      <td>Dear Principal,\\n\\nI have heard you are having...</td>\n",
       "      <td>1CE6C10B9683</td>\n",
       "      <td>dyer</td>\n",
       "      <td>wrong word</td>\n",
       "      <td>1137</td>\n",
       "      <td>1141</td>\n",
       "      <td>1718398530582</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.683321</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rfQv3LPBikeoFIE1NyA3</td>\n",
       "      <td>ms</td>\n",
       "      <td>Some of your friends perform community service...</td>\n",
       "      <td>Dear Principal,\\n\\nI have heard you are having...</td>\n",
       "      <td>1CE6C10B9683</td>\n",
       "      <td>know it may sound funny but picking up trash ...</td>\n",
       "      <td>run-on sentence</td>\n",
       "      <td>1267</td>\n",
       "      <td>1487</td>\n",
       "      <td>1718398574934</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.426005</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rfQv3LPBikeoFIE1NyA3</td>\n",
       "      <td>ms</td>\n",
       "      <td>Some of your friends perform community service...</td>\n",
       "      <td>Dear Principal,\\n\\nI have heard you are having...</td>\n",
       "      <td>1CE6C10B9683</td>\n",
       "      <td>or example if one student did community servic...</td>\n",
       "      <td>Good example</td>\n",
       "      <td>791</td>\n",
       "      <td>875</td>\n",
       "      <td>1718398626223</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.460753</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    tid grade  \\\n",
       "0  rfQv3LPBikeoFIE1NyA3    ms   \n",
       "1  rfQv3LPBikeoFIE1NyA3    ms   \n",
       "2  rfQv3LPBikeoFIE1NyA3    ms   \n",
       "3  rfQv3LPBikeoFIE1NyA3    ms   \n",
       "4  rfQv3LPBikeoFIE1NyA3    ms   \n",
       "\n",
       "                                              prompt  \\\n",
       "0  Some of your friends perform community service...   \n",
       "1  Some of your friends perform community service...   \n",
       "2  Some of your friends perform community service...   \n",
       "3  Some of your friends perform community service...   \n",
       "4  Some of your friends perform community service...   \n",
       "\n",
       "                                               essay       essayid  \\\n",
       "0  Dear Principal,\\n\\nI have heard you are having...  1CE6C10B9683   \n",
       "1  Dear Principal,\\n\\nI have heard you are having...  1CE6C10B9683   \n",
       "2  Dear Principal,\\n\\nI have heard you are having...  1CE6C10B9683   \n",
       "3  Dear Principal,\\n\\nI have heard you are having...  1CE6C10B9683   \n",
       "4  Dear Principal,\\n\\nI have heard you are having...  1CE6C10B9683   \n",
       "\n",
       "                                             excerpt  \\\n",
       "0                                                 i    \n",
       "1                                                e a   \n",
       "2                                               dyer   \n",
       "3   know it may sound funny but picking up trash ...   \n",
       "4  or example if one student did community servic...   \n",
       "\n",
       "                          feedback  startidx  endidx      commentid  ...  \\\n",
       "0  Capital and introductory phrase       255     258  1718398386391  ...   \n",
       "1              Introductory phrase       548     551  1718398439880  ...   \n",
       "2                       wrong word      1137    1141  1718398530582  ...   \n",
       "3                  run-on sentence      1267    1487  1718398574934  ...   \n",
       "4                     Good example       791     875  1718398626223  ...   \n",
       "\n",
       "  gr_count  gr_rate  content_word_density  uptake cosine_similarity  \\\n",
       "0        0      0.0                  0.75  0.0000          0.507323   \n",
       "1        0      0.0                  1.00  0.0000          0.654442   \n",
       "2        1      0.5                  1.00  0.0000          0.683321   \n",
       "3        1      0.5                  1.00  0.0000          0.426005   \n",
       "4        0      0.0                  1.00  0.0625          0.460753   \n",
       "\n",
       "   pronoun_fps  pronoun_sp  pronoun_fpp  wh_question_count  \\\n",
       "0            0           0            0                  0   \n",
       "1            0           0            0                  0   \n",
       "2            0           0            0                  0   \n",
       "3            0           0            0                  0   \n",
       "4            0           0            0                  0   \n",
       "\n",
       "   yes_no_question_count  \n",
       "0                      0  \n",
       "1                      0  \n",
       "2                      0  \n",
       "3                      0  \n",
       "4                      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "df = pd.read_csv('human_meta_pt1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['feedback'] = df['feedback'].astype(str)\n",
    "df['excerpt'] = df['excerpt'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non-Dialogic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mxtan/.local/lib/python3.8/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "  0%|          | 0/385 [00:00<?, ?it/s]/home/mxtan/.local/lib/python3.8/site-packages/transformers/pipelines/base.py:1157: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "100%|██████████| 385/385 [00:02<00:00, 139.63it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from transformers import pipeline\n",
    "pipe = pipeline(\"text-classification\", model=\"meiflwr/nondialogic_feedback\", device = 0)\n",
    "def get_dro(excerpt, feedback):\n",
    "    out = []\n",
    "    dro_out = pipe([{'text': feedback, 'text_pair': excerpt}])\n",
    "    if dro_out[0]['label'] == 'LABEL_1':\n",
    "        out.append(1)\n",
    "    else:\n",
    "        out.append(0)\n",
    "    return out\n",
    "\n",
    "tqdm.pandas()\n",
    "df['ND'] = df.progress_apply(lambda row: get_dro(row['excerpt'], row['feedback']), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non-Revision-Oriented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mxtan/.local/lib/python3.8/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "100%|██████████| 385/385 [00:11<00:00, 32.91it/s]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "pipe = pipeline(\"text-classification\", model=\"meiflwr/nonrevisionoriented_feedback\")\n",
    "def get_dro(excerpt, feedback):\n",
    "    out = []\n",
    "    dro_out = pipe([{'text': feedback, 'text_pair': excerpt}])\n",
    "    if dro_out[0]['label'] == 'LABEL_1':\n",
    "        out.append(1)\n",
    "    else:\n",
    "        out.append(0)\n",
    "    return out\n",
    "\n",
    "tqdm.pandas()\n",
    "df['NRO'] = df.progress_apply(lambda row: get_dro(row['excerpt'], row['feedback']), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pure Praise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mxtan/.local/lib/python3.8/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "100%|██████████| 385/385 [00:12<00:00, 30.64it/s]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "pipe = pipeline(\"text-classification\", model=\"meiflwr/praise_feedback\")\n",
    "def get_dro(excerpt, feedback):\n",
    "    out = []\n",
    "    dro_out = pipe([{'text': feedback, 'text_pair': excerpt}])\n",
    "    if dro_out[0]['label'] == 'LABEL_1':\n",
    "        out.append(1)\n",
    "    else:\n",
    "        out.append(0)\n",
    "    return out\n",
    "\n",
    "tqdm.pandas()\n",
    "df['PP'] = df.progress_apply(lambda row: get_dro(row['excerpt'], row['feedback']), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Power-Affirming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mxtan/.local/lib/python3.8/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "  0%|          | 0/385 [00:00<?, ?it/s]/home/mxtan/.local/lib/python3.8/site-packages/transformers/pipelines/base.py:1157: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "100%|██████████| 385/385 [00:02<00:00, 128.95it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "# Use a pipeline as a high-level helper\n",
    "from transformers import pipeline\n",
    "pipe = pipeline(\"text-classification\", model=\"meiflwr/power-affirming-feedback\", device = 0)\n",
    "def get_pa(excerpt, feedback):\n",
    "  reward = pipe([{'text': feedback, 'text_pair': excerpt}])\n",
    "  return reward[0]['score']\n",
    "\n",
    "tqdm.pandas()\n",
    "df['pa_mean'] = df.progress_apply(lambda row: get_pa(row['excerpt'], row['feedback']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5671552028748896"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['pa_mean'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mxtan/.local/lib/python3.8/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "100%|██████████| 385/385 [00:11<00:00, 32.42it/s]\n",
      "100%|██████████| 385/385 [00:11<00:00, 32.19it/s]\n",
      "100%|██████████| 385/385 [00:11<00:00, 33.14it/s]\n"
     ]
    }
   ],
   "source": [
    "# Use a pipeline as a high-level helper\n",
    "from transformers import pipeline\n",
    "pipe1 = pipeline(\"text-classification\", model=\"meiflwr/poweraffirming_feedback_skew1\")\n",
    "pipe2 = pipeline(\"text-classification\", model=\"meiflwr/poweraffirming_feedbak_skew2\")\n",
    "pipe3 = pipeline(\"text-classification\", model=\"meiflwr/poweraffirming_feedback_skew3\")\n",
    "\n",
    "def get_pa(excerpt, feedback, pipeline):\n",
    "  reward = pipeline([{'text': feedback, 'text_pair': excerpt}])\n",
    "  return reward[0]['score']\n",
    "\n",
    "tqdm.pandas()\n",
    "df['pa1'] = df.progress_apply(lambda row: get_pa(row['excerpt'], row['feedback'], pipe1), axis=1)\n",
    "df['pa2'] = df.progress_apply(lambda row: get_pa(row['excerpt'], row['feedback'], pipe2), axis=1)\n",
    "df['pa3'] = df.progress_apply(lambda row: get_pa(row['excerpt'], row['feedback'], pipe3), axis=1)\n",
    "\n",
    "# Calculate the variance of the pa-scores\n",
    "df['pa_var'] = df[['pa1', 'pa2', 'pa3']].var(axis=1)\n",
    "df['pa_mean2'] = df[['pa1', 'pa2', 'pa3']].mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5651473980445366\n",
      "0.5648816309191964\n",
      "0.5653255993669684\n",
      "0.565118209443567\n"
     ]
    }
   ],
   "source": [
    "print(df['pa1'].mean())\n",
    "print(df['pa2'].mean())\n",
    "print(df['pa3'].mean())\n",
    "print(df['pa_mean2'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('human_res_asap_meta.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs224n",
   "language": "python",
   "name": "cs224n"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
